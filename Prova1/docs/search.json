[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Prova 1 - Aprendizagem de Máquina",
    "section": "",
    "text": "Questão 1:\nDisserte sobre o processo de treinamento de modelo de regressão em aprendizagem de máquina. Explique cada um dos passos considerando a imagem que segue:\n\nNão esqueça de explicar:\n1. O que é a validação cruzada e qual a diferença entre o leave-one-out e o k-fold cross-validation;\n2. O que é o risco preditivo do modelo e qual seu estimador;\n3. A importância de se ter uma base de dados de teste para avaliação final do modelo.\n\nResposta: No processo de treinamento de um modelo de regressão em aprendizagem de máquina, primeimeiramente fazemos o data spliting dos dados, ou seja, a divisão dos dados que usualmente é dividida em treino, validação e teste, onde no conjunto de treino realizamos o ajuste do modelo que melhor se adaptou aos dados, no conjunto de validação fazemos a tunagem de hiperparâmetros do modelo, e no conjunto de teste é onde avaliamos o desempenho do modelo final escolhido por meio do risco preditivo. A validação cruzada consiste na divisão dos dados em treino e validação, em que no leave-one-out cross validation a cada iteração tiramos de fora uma única observação para teste e treinamos o modelo com as observações que ficaram, assim consequentemente, iremos ter \\(n\\) modelos ajustados, em que \\(n\\) é o número de observações total na base de dados. Já no k-fold cross validation iremos ter \\(k\\) modelos finais ajustados, em que \\(k\\) é o número de lotes, onde a cada iteração um determinado lote será utilizado para teste e o restante das observações serão usadas para treinar o modelo. O risco preditivo avalia o desempenho do modelo ajustado, no qual o Erro Quadrático Médio (EQM) geralmente é utilizado como medida para avaliar este desempenho, onde o EQM é a média do quadrado dos erros entre os valores observados e os valores preditos pelo modelo. É importante termos uma base de dados somente de teste para avaliação do modelo final, pois é nela que verificamos a capacidade de generalização do modelo.\n\n\n\nQuestão 2:\nConsidere o modelo de regressão real definido pela equação abaixo:\n\\[r(x) = 2.76 + 0.5x_1 - 0.75x_2 + 0.5x_3 - 0.75x_4 + x_5 + \\sum_{i=6}^{30} 0x_i + \\epsilon,\\]\nem que \\(\\epsilon \\sim N(0,0.5^2)\\) e \\(x_i \\sim N(0,1)\\), \\(\\forall{i} = 1, ..., 30\\). Treine um modelo de regressão linear múltipla e estime o risco preditivo do modelo.\n\nDicas:\n1. Considere uma base de dados com \\(n=1000\\) observações e \\(31\\) colunas;\n2. Note que \\(X\\) será uma matriz de features (recursos/covariáveis) com \\(31\\) colunas, sendo a primeira coluna composta por \\(1’s\\) (por conta do intercepto) e as demais colunas compostas por valores aleatórios de uma distribuição normal padrão, conforme mencionado anteriormente, i.e., \\(x_i \\sim N(0,1), \\forall{i}\\);\n3. Note que não há hiperparâmetros a serem ajustados, diferentemente da regressão polinomial que vimos em sala de aula;\n4. Não havendo hiperparâmetros, você precisa apenas dividir a base de dados entre treino e teste, isto é, realizar o hold-out;\n5. Ajuste o modelo na base de dados considerando o conjunto de treino;\n6. Avalie o modelo na base de teste.\n\nResposta:\n\n\nCode\nrm(list=ls())\nlibrary(tidymodels)\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n\n\n✔ broom        1.0.6     ✔ recipes      1.1.0\n✔ dials        1.3.0     ✔ rsample      1.2.1\n✔ dplyr        1.1.4     ✔ tibble       3.2.1\n✔ ggplot2      3.5.1     ✔ tidyr        1.3.1\n✔ infer        1.0.7     ✔ tune         1.2.1\n✔ modeldata    1.4.0     ✔ workflows    1.1.4\n✔ parsnip      1.2.1     ✔ workflowsets 1.1.0\n✔ purrr        1.0.2     ✔ yardstick    1.3.1\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Learn how to get started at https://www.tidymodels.org/start/\n\n\nCode\ntidymodels_prefer()\n\nn = 1000\n\n# Modelo real que não conhecemos\nrandom_real &lt;- function(n){\n  x &lt;- rnorm(n, 0, 1)\n    runif(n, 8, 18)\n  y &lt;- 2.76 + 0.5*x1 - 0.75*x2 + 0.5*x3 - 0.75*x4  + x5 + sum(xi) + rnorm(n, 0, 0.5)\n  tibble(x = x, y = y)\n}\n\n\n\n\nQuestão 3:\nConsidere o modelo de regressão real dado por: \\[r(x) = 1.6 + 5\\sin(x) - 8x^2 + \\epsilon,\\]\nem que \\(x \\sim U(0,20)\\) e \\(\\epsilon \\sim N(0,1)\\) (normal padrão). Treine modelos de regressão polinomial com o grau do polinômio \\(p=1,2,3\\) e estime o risco preditivo de cada um dos modelos.\n\nDicas:\n1. Considere \\(n = 10000\\) observações;\n2. Não é necessário fazer fazer cross-validation;\n3. Apenas considere treino e teste;\n4. Ajuste cada um dos modelos no treino e estime o risco preditivo do modelo de cada um dos modelos no conjunto de teste.\n\nInterprete o resultado obtido.\n\n\nResposta:\n\n\nCode\nrm(list=ls())\n# Carregando as bibliotecas\nlibrary(tidymodels)\nlibrary(ggplot2)\nlibrary(tibble)\nlibrary(rsample)\nlibrary(patchwork)\nlibrary(tidyverse)\n\ntidymodels_prefer()\n\n# Modelo real que não conhecemos\nrandom_real &lt;- function(n){\n  x &lt;- runif(n = n, min = 0, max = 20)\n  # Essa é a regressão real\n  y &lt;- 1.6 + 5*sin(x) - 8*(x^2) + rnorm(n, mean = 0, sd = 1)\n\n  tibble(x = x, y = y)\n}\n\n# Funções para treinar\ntreinar &lt;- function(p, dados_treino){\n  # Criando uma regressao polinomial\n  lm(data = dados_treino, y ~ poly(x, degree = p, raw = TRUE))\n}\n\n# Função para testar\nteste &lt;- function(modelo, dados_teste){\n  # Calculando o erro quadrático médio\n  dados_teste %&gt;%\n    mutate(\n      y_hat = predict(modelo, newdata = dados_teste) # Aqui calculo y chapeu\n    ) %&gt;%\n    summarise(\n      eqm = mean((y - y_hat)^2)\n    )\n}\n\n# Função para avaliar o modelo\navaliacao_eqm &lt;- function(p, dados_treino, dados_teste){\n\n  # Treinando o modelo\n  ajuste &lt;- treinar(p, dados_treino)\n\n  # Calculando o erro quadrático médio\n  eqm &lt;- teste(ajuste, dados_teste)\n\n  list(ajuste = ajuste, eqm = as.numeric(eqm[1,1]))\n}\n\n\n\n\nCode\n# Fixando semente\nset.seed(0)\n\n# Gerando a base total de dados com 10000 observações\ndados &lt;- random_real(n = 10000)\n\n#  Realizando o Hold-out\ndados_divididos &lt;- rsample::initial_split(dados, prop = 0.8, strata = y)\ndados_treino &lt;- rsample::training(dados_divididos)\ndados_teste &lt;- rsample::testing(dados_divididos)\ngrau_maximo &lt;- 3\n\n# Avaliando o erro quadrático médio para cada grau\nvec_eqm &lt;-\n  purrr::map_dbl(\n    .x = 1L:grau_maximo,\n    .f = \\(p) avaliacao_eqm(p = p, dados_treino = dados_treino, dados_teste = dados_teste)$eqm\n  )\n\n\n\n\nCode\n# Tabela com os EQM's e seus respectivos graus de polinômio\ndados_eqm &lt;- tibble(p = 1L:grau_maximo, eqm = vec_eqm)\ndados_eqm\n\n\n# A tibble: 3 × 2\n      p     eqm\n  &lt;int&gt;   &lt;dbl&gt;\n1     1 56140. \n2     2    12.5\n3     3    12.3\n\n\n\n\nCode\n# Melhor grau do polinômio que tem o menor EQM\nmelhor_p &lt;- which.min(vec_eqm)\nmelhor_p\n\n\n[1] 3\n\n\n\n\nCode\n# Ajustando a regressão verdadeira com grau 1 sobre os dados\najuste1 &lt;- treinar(p = 1, dados_treino = dados_teste)\najuste1\n\n\n\nCall:\nlm(formula = y ~ poly(x, degree = p, raw = TRUE), data = dados_treino)\n\nCoefficients:\n                    (Intercept)  poly(x, degree = p, raw = TRUE)  \n                          538.6                           -160.6  \n\n\n\n\nCode\n# Ajustando a regressão verdadeira com grau 2 sobre os dados\najuste2 &lt;- treinar(p = 2, dados_treino = dados_teste)\najuste2\n\n\n\nCall:\nlm(formula = y ~ poly(x, degree = p, raw = TRUE), data = dados_treino)\n\nCoefficients:\n                     (Intercept)  poly(x, degree = p, raw = TRUE)1  \n                          4.1746                           -0.5012  \npoly(x, degree = p, raw = TRUE)2  \n                         -7.9806  \n\n\n\n\nCode\n# Ajustando a regressão verdadeira com grau 3 sobre os dados\najuste3 &lt;- treinar(p = 3, dados_treino = dados_teste)\najuste3\n\n\n\nCall:\nlm(formula = y ~ poly(x, degree = p, raw = TRUE), data = dados_treino)\n\nCoefficients:\n                     (Intercept)  poly(x, degree = p, raw = TRUE)1  \n                        5.265589                         -1.148003  \npoly(x, degree = p, raw = TRUE)2  poly(x, degree = p, raw = TRUE)3  \n                       -7.900008                         -0.002684  \n\n\nObserva-se que o melhor o modelo de regressão polinomial é o de grau 3, pois apresentou menor erro quadrático médio.\n\n\n\nQuestão 4:\nConsidere a base de dados referente à vendas de sorvetes. A base de dados contém as seguintes variáveis:\n1. Temperatura: temperatura média do dia;\n2. Vendas: quantidade de sorvetes vendidos no dia.\n\nDownload: Para baixar os dados, acesse o link e clique em “Download”, no canto superior direito.\n\nEstamos interessados em estimar as vendas de sorvetes dado a temperatura. Dessa forma, considere o número de vendas como sendo o label (variável \\(y\\)) e as temperaturas como sendo as features (variáveis \\(x\\)).\n\nConsiderando a base de dados fornecida, treine um modelo de regressão polinomial com grau \\(p = 1,2,3,4,5\\) e estime o risco preditivo do modelo selecionado. Além disso, construa um gráfico do modelo selecionado ajustado aos dados.\n\nDicas:\n1. Considere utilizar um esquema de validação cruzada para selecionar o melhor hiperparâmetro;\n2. Com o grau de polinômio escolhido, treine o modelo na base de dados de treino e avalie o risco desse modelo no conjunto de teste;\n3. Considere uma divisão inicial (hold-out) na proporção \\(80\\%\\) (treino) e \\(20\\%\\) para teste.\n\nResposta:\n\n\nCode\nrm(list=ls())\n# Carregando os pacotes\nlibrary(tidymodels)\nlibrary(ggplot2)\nlibrary(tibble)\nlibrary(rsample)\nlibrary(patchwork)\nlibrary(tidyverse)\nlibrary(corrr)\n\ntidymodels::tidymodels_prefer()\n\n# Carregando a base de dados\ndados &lt;- read.csv(\"~/JOANA/ESTATÍSTICA/2024.1/Aprendizagem de Máquina/AM/Prova1/dados/Ice_cream.csv\", sep = \",\",\n                  col.names = c(\"temperatura\",\"vendas\"))\n\n# Renomeando as variáveis\ndados &lt;- dados %&gt;% dplyr::rename(x = temperatura, y = vendas)\n\n# Fixando a semente\nset.seed(0)\n\n# Realizadon hold-out\ndados_split &lt;- rsample::initial_split(dados, prop = 0.8, strata = \"y\")\ntreino &lt;- rsample::training(dados_split)\nteste &lt;- rsample::testing(dados_split)\n\n# Fazendo validação cruzada\ncv &lt;- vfold_cv(treino, v = 5)\n\n# Definindo o modelo\nmodelo &lt;-\n  parsnip::linear_reg() %&gt;%\n  parsnip::set_engine(\"lm\") %&gt;%\n  parsnip::set_mode(\"regression\")\n\n\n# Definindo receita\nreceita &lt;-\n  recipe(y ~ ., data = treino) %&gt;%\n  recipes::step_poly(\n      all_numeric_predictors(),\n      degree = tune(\"p\"),\n      options = list(raw = TRUE)\n    )\n\n# Validacação cruzada\ncv &lt;- vfold_cv(treino, v = 5)\n\n# Criando o workflow\nwf &lt;-\n  workflow() %&gt;%\n  add_recipe(receita) %&gt;%\n  add_model(modelo)\n\n# Extraindo hiperparametros do modelo\nparametros &lt;-\n  wf %&gt;%\n  extract_parameter_set_dials() %&gt;% # Extraindo os hiperparâmetros do modelo\n  extract_parameter_dials(\"p\") %&gt;%\n  range_set(range = c(1, 5)) %&gt;%\n  parameters()\n\nparametros$id &lt;- \"p\"\n\n# Tunando o modelo\ntunagem &lt;- tune_grid(\n  wf,\n  resamples = cv,\n  grid = tibble(p = 1:5), # Parâmetros que desejamos que ele teste\n  metrics = metric_set(rmse)\n)\n\n# Coletando as métricas e o melhor grau\ncollect_metrics(tunagem)\n\n\n# A tibble: 5 × 7\n      p .metric .estimator  mean     n std_err .config             \n  &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1     1 rmse    standard   12.7      5   1.41  Preprocessor1_Model1\n2     2 rmse    standard    3.66     5   0.407 Preprocessor2_Model1\n3     3 rmse    standard    4.51     5   1.35  Preprocessor3_Model1\n4     4 rmse    standard    4.20     5   1.53  Preprocessor4_Model1\n5     5 rmse    standard    5.02     5   2.35  Preprocessor5_Model1\n\n\n\n\nCode\n# Visualizando o melhor grau segundo a métrica RMSE\nshow_best(tunagem, n = 1, metric = \"rmse\")\n\n\n# A tibble: 1 × 7\n      p .metric .estimator  mean     n std_err .config             \n  &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1     2 rmse    standard    3.66     5   0.407 Preprocessor2_Model1\n\n\n\n\nCode\n# Selecionado o melhor \"p\"\nmelhor_p &lt;- select_best(tunagem, metric = \"rmse\")\nmelhor_p\n\n\n# A tibble: 1 × 2\n      p .config             \n  &lt;int&gt; &lt;chr&gt;               \n1     2 Preprocessor2_Model1\n\n\nO melhor grau de polinômio é 2, segundo a métrica RMSE.\n\n\n\nCode\n# Finalizando\nwf &lt;-\n  wf %&gt;%\n  finalize_workflow(melhor_p)\n\n# Realizando o ajuste final do modelo\najuste &lt;- last_fit(wf, dados_split, metrics = metric_set(rmse))\n\n# Olhando o desempenho no teste\ncollect_metrics(ajuste)\n\n\n# A tibble: 1 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard        3.08 Preprocessor1_Model1\n\n\n\n\nCode\nreal_vs_estimado &lt;- collect_predictions(ajuste)\n\nreal_vs_estimado %&gt;%\n  ggplot(aes(x = .pred, y = y)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"tomato\") +\n  labs(\n    title = \"Real vs Estimado\",\n    subtitle = \"Base de teste\",\n    x = \"Previsões\",\n    y = \"Observações\"\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Prevendo\ndados_qualquer &lt;- sample_n(dados, 10) # Seleciona 10 linhas quaisquer de dados.\nwf_modelo &lt;- extract_workflow(ajuste)\nvalores_previstos &lt;- predict(wf_modelo, new_data = dados_qualquer)\n\n# Visualizando lado a lado, y e valores previstos\ndplyr::bind_cols(dados_qualquer, valores_previstos)\n\n\n             x          y     .pred\n1  -2.28826400 18.1239912 14.495141\n2   3.70405744 17.8439565 24.299832\n3  -2.65228679 20.2796792 18.075166\n4   2.07510060  8.1707349  8.807715\n5  -0.03389529  0.8976032  2.976671\n6   1.24071162  1.2923608  4.581507\n7  -1.17312327  6.6891226  6.504845\n8   4.13086796 34.5307427 29.942415\n9   2.31859124  7.4120940 10.514634\n10  3.33593241 26.1047404 19.961191\n\n\n\n\nCode\n# Prevendo o número de vendas de sorvetes em uma temperatura de 3 graus celsius\npredict(wf_modelo, new_data = tibble(x = 3))\n\n\n# A tibble: 1 × 1\n  .pred\n  &lt;dbl&gt;\n1  16.4\n\n\nEstima-se que o número de vendas de sorvetes em uma temperatura de 3 graus celsius é de aproximadamente 16 unidades.\n\n\n\nQuestão 5:\nConsidere o modelo de regressão real dado por: \\[r(x) = 45 \\times tanh\\left(\\frac{x}{1.9} - 7\\right) + 57 + \\epsilon,\\]\nem que \\(x\\) são observações de uma variável aleatória \\(X \\sim U(0,18)\\) e \\(\\epsilon \\sim N(0,4)\\). Considerando um conjunto de dados de 10 mil observações, treine um modelo de regressão polinomial com grau \\(p=1, ..., 15\\). Estime o risco preditivo do melhor modelo. Construa um gráfico do melhor modelo ajustando aos dados de teste, i.e., \\(y\\) versus \\(\\hat{y}\\) do conjunto de teste.\n\nResposta:\n\n\nCode\nrm(list=ls())\n# Carregando as bibliotecas\nlibrary(tidymodels)\nlibrary(ggplot2)\nlibrary(tibble)\nlibrary(rsample)\nlibrary(patchwork)\n\n# Modelo real que não conhecemos\nrandom_real &lt;- function(n){\n  x &lt;- runif(n = n, min = 0, max = 18)\n  # Regressão real\n  y &lt;- 45 * tanh(x/1.9 - 7) + 57  + rnorm(n, 0, 2)\n\n  tibble(x = x, y = y)\n}\n\n# Função para treinar o modelo\ntreinar &lt;- function(p, dados_treino){\n  # Criando uma regressao polinomial\n  lm(data = dados_treino, y ~ poly(x, degree = p, raw = TRUE))\n}\n\n# Função para testar o modelo\nteste &lt;- function(modelo, dados_teste){\n  # Calculando o erro quadrático médio\n  dados_teste %&gt;%\n    mutate(\n      y_hat = predict(modelo, newdata = dados_teste) # Aqui calculo y chapeu\n    ) %&gt;%\n    summarise(\n      eqm = mean((y - y_hat)^2)\n    )\n}\n\n# Função para avaliar o erro quadrático médio\navaliacao_eqm &lt;- function(p, dados_treino, dados_teste){\n\n  # Treinando o modelo\n  ajuste &lt;- treinar(p, dados_treino)\n\n  # Calculando o erro quadrático médio\n  eqm &lt;- teste(ajuste, dados_teste)\n\n  list(ajuste = ajuste, eqm = as.numeric(eqm[1,1]))\n}\n\n\n\n\nCode\n# Fixando semente\nset.seed(0)\n\n# Gerando a base total de dados com 10000 observações\ndados &lt;- random_real(n = 10000)\n\n# Realizando o Hold-out\ndados_divididos &lt;- rsample::initial_split(dados, prop = 0.8, strata = y)\ndados_treino &lt;- rsample::training(dados_divididos)\ndados_teste &lt;- rsample::testing(dados_divididos)\ngrau_maximo &lt;- 15\n\n# Avaliando o erro quadrático médio para cada grau de polinômio\nvalores &lt;-\n  purrr::map_dbl(\n    .x = 1L:grau_maximo,\n    .f = \\(p) avaliacao_eqm(p = p, dados_treino = dados_treino, dados_teste = dados_teste)$eqm\n  )\n\n# Melhor grau de polinômio\nmelhor_p &lt;- which.min(valores)\nmelhor_p\n\n\n[1] 14\n\n\n\n\nCode\n# Ajustando a regressão verdadeira com melhor_p sobre os dados\najuste &lt;- treinar(p = melhor_p, dados_treino = dados_teste)\n\n# Visualizando os dados e a regressão real\np &lt;- ggplot(data = dados_teste, aes(x = x, y = y)) +\n  geom_point() +\n  theme_minimal() +\n  ggtitle(\"Dados reais\") +\n  stat_function(fun = function(x) 45 * tanh(x/1.9 - 7) + 57, col = \"red\", linewidth = 1.2)\n\n# Visualizando o ajuste\np_ajuste &lt;-\n  p +\n  geom_function(fun = function(x) predict(ajuste, newdata = tibble(x = x)), col = \"blue\", linewidth = 1.2) +\n  ggtitle(\"Ajuste\") +\n  labs(x = \"x\", y = \"y\")\n\n# Visualizando os EQM's\np_eqm &lt;-\n  tibble(p = 1L:grau_maximo, eqm = valores) %&gt;%\n  ggplot(aes(x = p, y = eqm)) +\n  geom_line(linetype = \"dotted\", linewidth = 1) +\n  annotate(\"point\", x = melhor_p, y = valores[melhor_p], col = \"red\", size = 4, alpha = 0.7) +\n  theme_minimal() +\n  ggtitle(\"EQM\") +\n  labs(x = \"p\", y = \"EQM\") +\n  scale_y_log10()\n\np + p_ajuste + p_eqm\n\n\n\n\n\n\n\n\n\nNota-se que o melhor modelo de regressão polinomial é o de grau 14. O gráfico acima mostra a regressão real (em vermelho) e o ajuste do modelo de regressão polinomial de grau 14 (em azul) sobre os dados de teste. Além disso, o gráfico de EQM mostra que o modelo de grau 14 é o que apresenta menor Erro Quadrático Médio."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  }
]