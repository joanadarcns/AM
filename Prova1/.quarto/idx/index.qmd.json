{"title":"Prova 1 - Aprendizagem de Máquina","markdown":{"yaml":{"title":"Prova 1 - Aprendizagem de Máquina","author":"Joana D'arc Nunes da Silva, Matrícula: 20180078535","date":"last-modified","date-format":"DD MMM, YYYY","format":{"html":{"theme":"lux","code-fold":"show","code-tools":false,"code-block-bg":true,"code-block-border-left":"#9400D3","highlight-style":"github","code-link":true,"toc":true,"toc-title":"Sumário","toc-location":"left","toc-depth":2,"number-sections":false,"number-depth":3,"smooth-scroll":true,"link-external-newwindow":true}},"fig-dpi":1000,"self-contained":true,"page-layout":"full","editor":"source"},"headingText":"Questão 1:","containsRefs":false,"markdown":"\n\n\nDisserte sobre o processo de treinamento de modelo de regressão em aprendizagem de máquina. Explique cada um dos passos considerando a imagem que segue:\\\n![](C:/Users/luiza/OneDrive/Documentos/JOANA/ESTATÍSTICA/2024.1/Aprendizagem de Máquina/AM/Prova1/dados/imagem_questao1_AM_p1.png){width=\"70%\"}\\\nNão esqueça de explicar:\\\n1. O que é a validação cruzada e qual a diferença entre o *leave-one-out* e o *k-fold cross-validation*;\\\n2. O que é o risco preditivo do modelo e qual seu estimador;\\\n3. A importância de se ter uma base de dados de teste para avaliação final do modelo.\\\n\n`Resposta:` No processo de treinamento de um modelo de regressão em aprendizagem de máquina, primeimeiramente fazemos o *data spliting* dos dados, ou seja, a divisão dos dados que usualmente é dividida em treino, validação e teste, onde no conjunto de treino realizamos o ajuste do modelo que melhor se adaptou aos dados, no conjunto de validação fazemos a tunagem de hiperparâmetros do modelo, e no conjunto de teste é onde avaliamos o desempenho do modelo final escolhido por meio do risco preditivo. A validação cruzada consiste na divisão dos dados em treino e validação, em que no *leave-one-out cross validation* a cada iteração tiramos de fora uma única observação para teste e treinamos o modelo com as observações que ficaram, assim consequentemente, iremos ter $n$ modelos ajustados, em que $n$ é o número de observações total na base de dados. Já no *k-fold cross validation* iremos ter $k$ modelos finais ajustados, em que $k$ é o número de lotes, onde a cada iteração um determinado lote será utilizado para teste e o restante das observações serão usadas para treinar o modelo. O risco preditivo avalia o desempenho do modelo ajustado, no qual o Erro Quadrático Médio (EQM) geralmente é utilizado como medida para avaliar este desempenho, onde o EQM é a média do quadrado dos erros entre os valores observados e os valores preditos pelo modelo. É importante termos uma base de dados somente de teste para avaliação do modelo final, pois é nela que verificamos a capacidade de generalização do modelo.\\\n\n# Questão 2:\n\nConsidere o modelo de regressão real definido pela equação abaixo:\\\n$$r(x) = 2.76 + 0.5x_1 - 0.75x_2 + 0.5x_3 - 0.75x_4 + x_5 + \\sum_{i=6}^{30} 0x_i + \\epsilon,$$\\\nem que $\\epsilon \\sim N(0,0.5^2)$ e $x_i \\sim N(0,1)$, $\\forall{i} = 1, ..., 30$. Treine um modelo de regressão linear múltipla e estime o risco preditivo do modelo.\\\n\n**Dicas:**\\\n1. Considere uma base de dados com $n=1000$ observações e $31$ colunas;\\\n2. Note que $X$ será uma matriz de *features* (recursos/covariáveis) com $31$ colunas, sendo a primeira coluna composta por $1’s$ (por conta do intercepto) e as demais colunas compostas por valores aleatórios de uma distribuição normal padrão, conforme mencionado anteriormente, i.e., $x_i \\sim N(0,1), \\forall{i}$;\\\n3. Note que não há hiperparâmetros a serem ajustados, diferentemente da regressão polinomial que vimos em sala de aula;\\\n4. Não havendo hiperparâmetros, você precisa apenas dividir a base de dados entre treino e teste, isto é, realizar o *hold-out*;\\\n5. Ajuste o modelo na base de dados considerando o conjunto de treino;\\\n6. Avalie o modelo na base de teste.\\\n\n`Resposta:`\n\n```{r, warning=FALSE}\nrm(list=ls())\nlibrary(tidymodels)\n\ntidymodels_prefer()\n\nn = 1000\n\n# Modelo real que não conhecemos\nrandom_real <- function(n){\n  x <- rnorm(n, 0, 1)\n    runif(n, 8, 18)\n  y <- 2.76 + 0.5*x1 - 0.75*x2 + 0.5*x3 - 0.75*x4  + x5 + sum(xi) + rnorm(n, 0, 0.5)\n  tibble(x = x, y = y)\n}\n```\n\n# Questão 3:\n\nConsidere o modelo de regressão real dado por: $$r(x) = 1.6 + 5\\sin(x) - 8x^2 + \\epsilon,$$\\\nem que $x \\sim U(0,20)$ e $\\epsilon \\sim N(0,1)$ (normal padrão). Treine modelos de regressão polinomial com o grau do polinômio $p=1,2,3$ e estime o risco preditivo de cada um dos modelos.\\\n\n**Dicas:**\\\n1. Considere $n = 10000$ observações;\\\n2. Não é necessário fazer fazer *cross-validation*;\\\n3. Apenas considere treino e teste;\\\n4. Ajuste cada um dos modelos no treino e estime o risco preditivo do modelo de cada um dos modelos no conjunto de teste.\\\n\nInterprete o resultado obtido.\n\n![](C:/Users/luiza/OneDrive/Documentos/JOANA/ESTATÍSTICA/2024.1/Aprendizagem de Máquina/AM/Prova1/dados/imagem_questao3_AM_p1.png){width=\"70%\"}\\\n\n`Resposta:`\n\n```{r, warning=FALSE, message=FALSE}\nrm(list=ls())\n# Carregando as bibliotecas\nlibrary(tidymodels)\nlibrary(ggplot2)\nlibrary(tibble)\nlibrary(rsample)\nlibrary(patchwork)\nlibrary(tidyverse)\n\ntidymodels_prefer()\n\n# Modelo real que não conhecemos\nrandom_real <- function(n){\n  x <- runif(n = n, min = 0, max = 20)\n  # Essa é a regressão real\n  y <- 1.6 + 5*sin(x) - 8*(x^2) + rnorm(n, mean = 0, sd = 1)\n\n  tibble(x = x, y = y)\n}\n\n# Funções para treinar\ntreinar <- function(p, dados_treino){\n  # Criando uma regressao polinomial\n  lm(data = dados_treino, y ~ poly(x, degree = p, raw = TRUE))\n}\n\n# Função para testar\nteste <- function(modelo, dados_teste){\n  # Calculando o erro quadrático médio\n  dados_teste %>%\n    mutate(\n      y_hat = predict(modelo, newdata = dados_teste) # Aqui calculo y chapeu\n    ) %>%\n    summarise(\n      eqm = mean((y - y_hat)^2)\n    )\n}\n\n# Função para avaliar o modelo\navaliacao_eqm <- function(p, dados_treino, dados_teste){\n\n  # Treinando o modelo\n  ajuste <- treinar(p, dados_treino)\n\n  # Calculando o erro quadrático médio\n  eqm <- teste(ajuste, dados_teste)\n\n  list(ajuste = ajuste, eqm = as.numeric(eqm[1,1]))\n}\n```\n\n```{r, warning=FALSE}\n# Fixando semente\nset.seed(0)\n\n# Gerando a base total de dados com 10000 observações\ndados <- random_real(n = 10000)\n\n#  Realizando o Hold-out\ndados_divididos <- rsample::initial_split(dados, prop = 0.8, strata = y)\ndados_treino <- rsample::training(dados_divididos)\ndados_teste <- rsample::testing(dados_divididos)\ngrau_maximo <- 3\n\n# Avaliando o erro quadrático médio para cada grau\nvec_eqm <-\n  purrr::map_dbl(\n    .x = 1L:grau_maximo,\n    .f = \\(p) avaliacao_eqm(p = p, dados_treino = dados_treino, dados_teste = dados_teste)$eqm\n  )\n```\n\n```{r, warning=FALSE}\n# Tabela com os EQM's e seus respectivos graus de polinômio\ndados_eqm <- tibble(p = 1L:grau_maximo, eqm = vec_eqm)\ndados_eqm\n```\n\n```{r, warning=FALSE}\n# Melhor grau do polinômio que tem o menor EQM\nmelhor_p <- which.min(vec_eqm)\nmelhor_p\n```\n\n```{r, warning=FALSE}\n# Ajustando a regressão verdadeira com grau 1 sobre os dados\najuste1 <- treinar(p = 1, dados_treino = dados_teste)\najuste1\n```\n\n```{r, warning=FALSE}\n# Ajustando a regressão verdadeira com grau 2 sobre os dados\najuste2 <- treinar(p = 2, dados_treino = dados_teste)\najuste2\n```\n\n```{r, warning=FALSE}\n# Ajustando a regressão verdadeira com grau 3 sobre os dados\najuste3 <- treinar(p = 3, dados_treino = dados_teste)\najuste3\n```\n\nObserva-se que o melhor o modelo de regressão polinomial é o de grau 3, pois apresentou menor erro quadrático médio.\\\n\n\n# Questão 4:\n\nConsidere a base de dados referente à vendas de sorvetes. A base de dados contém as seguintes variáveis:\\\n1. `Temperatura:` temperatura média do dia;\\\n2. `Vendas:` quantidade de sorvetes vendidos no dia.\\\n\n**Download:** Para baixar os dados, acesse o [link](https://www.kaggle.com/datasets/mirajdeepbhandari/polynomial-regression?select=Ice_cream+selling+data.csv) e clique em \"Download\", no canto superior direito.\\\n\nEstamos interessados em estimar as vendas de sorvetes dado a temperatura. Dessa forma, considere o número de vendas como sendo o *label* (variável $y$) e as temperaturas como sendo as *features* (variáveis $x$).\\\n\nConsiderando a base de dados fornecida, treine um modelo de regressão polinomial com grau $p = 1,2,3,4,5$ e estime o risco preditivo do modelo selecionado. Além disso, construa um gráfico do modelo selecionado ajustado aos dados.\\\n\n**Dicas:**\\\n1. Considere utilizar um esquema de validação cruzada para selecionar o melhor hiperparâmetro;\\\n2. Com o grau de polinômio escolhido, treine o modelo na base de dados de treino e avalie o risco desse modelo no conjunto de teste;\\\n3. Considere uma divisão inicial *(hold-out)* na proporção $80\\%$ (treino) e $20\\%$ para teste.\\\n\n`Resposta:`\n\n```{r, warning=FALSE}\nrm(list=ls())\n# Carregando os pacotes\nlibrary(tidymodels)\nlibrary(ggplot2)\nlibrary(tibble)\nlibrary(rsample)\nlibrary(patchwork)\nlibrary(tidyverse)\nlibrary(corrr)\n\ntidymodels::tidymodels_prefer()\n\n# Carregando a base de dados\ndados <- read.csv(\"~/JOANA/ESTATÍSTICA/2024.1/Aprendizagem de Máquina/AM/Prova1/dados/Ice_cream.csv\", sep = \",\",\n                  col.names = c(\"temperatura\",\"vendas\"))\n\n# Renomeando as variáveis\ndados <- dados %>% dplyr::rename(x = temperatura, y = vendas)\n\n# Fixando a semente\nset.seed(0)\n\n# Realizadon hold-out\ndados_split <- rsample::initial_split(dados, prop = 0.8, strata = \"y\")\ntreino <- rsample::training(dados_split)\nteste <- rsample::testing(dados_split)\n\n# Fazendo validação cruzada\ncv <- vfold_cv(treino, v = 5)\n\n# Definindo o modelo\nmodelo <-\n  parsnip::linear_reg() %>%\n  parsnip::set_engine(\"lm\") %>%\n  parsnip::set_mode(\"regression\")\n\n\n# Definindo receita\nreceita <-\n  recipe(y ~ ., data = treino) %>%\n  recipes::step_poly(\n      all_numeric_predictors(),\n      degree = tune(\"p\"),\n      options = list(raw = TRUE)\n    )\n\n# Validacação cruzada\ncv <- vfold_cv(treino, v = 5)\n\n# Criando o workflow\nwf <-\n  workflow() %>%\n  add_recipe(receita) %>%\n  add_model(modelo)\n\n# Extraindo hiperparametros do modelo\nparametros <-\n  wf %>%\n  extract_parameter_set_dials() %>% # Extraindo os hiperparâmetros do modelo\n  extract_parameter_dials(\"p\") %>%\n  range_set(range = c(1, 5)) %>%\n  parameters()\n\nparametros$id <- \"p\"\n\n# Tunando o modelo\ntunagem <- tune_grid(\n  wf,\n  resamples = cv,\n  grid = tibble(p = 1:5), # Parâmetros que desejamos que ele teste\n  metrics = metric_set(rmse)\n)\n\n# Coletando as métricas e o melhor grau\ncollect_metrics(tunagem)\n```\n\n\n```{r, warning=FALSE}\n# Visualizando o melhor grau segundo a métrica RMSE\nshow_best(tunagem, n = 1, metric = \"rmse\")\n```\n\n\n```{r, warning=FALSE}\n# Selecionado o melhor \"p\"\nmelhor_p <- select_best(tunagem, metric = \"rmse\")\nmelhor_p\n```\nO melhor grau de polinômio é 2, segundo a métrica RMSE.\\\n\n\n```{r, warning=FALSE}\n# Finalizando\nwf <-\n  wf %>%\n  finalize_workflow(melhor_p)\n\n# Realizando o ajuste final do modelo\najuste <- last_fit(wf, dados_split, metrics = metric_set(rmse))\n\n# Olhando o desempenho no teste\ncollect_metrics(ajuste)\n```\n\n\n```{r, warning=FALSE, message= FALSE}\nreal_vs_estimado <- collect_predictions(ajuste)\n\nreal_vs_estimado %>%\n  ggplot(aes(x = .pred, y = y)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"tomato\") +\n  labs(\n    title = \"Real vs Estimado\",\n    subtitle = \"Base de teste\",\n    x = \"Previsões\",\n    y = \"Observações\"\n  )\n```\n\n\n```{r, warning=FALSE}\n# Prevendo\ndados_qualquer <- sample_n(dados, 10) # Seleciona 10 linhas quaisquer de dados.\nwf_modelo <- extract_workflow(ajuste)\nvalores_previstos <- predict(wf_modelo, new_data = dados_qualquer)\n\n# Visualizando lado a lado, y e valores previstos\ndplyr::bind_cols(dados_qualquer, valores_previstos)\n```\n\n\n```{r, warning=FALSE}\n# Prevendo o número de vendas de sorvetes em uma temperatura de 3 graus celsius\npredict(wf_modelo, new_data = tibble(x = 3))\n\n```\n\nEstima-se que o número de vendas de sorvetes em uma temperatura de 3 graus celsius é de aproximadamente 16 unidades.\\\n\n\n# Questão 5:\n\nConsidere o modelo de regressão real dado por: $$r(x) = 45 \\times tanh\\left(\\frac{x}{1.9} - 7\\right) + 57 + \\epsilon,$$\\\nem que $x$ são observações de uma variável aleatória $X \\sim U(0,18)$ e $\\epsilon \\sim N(0,4)$. Considerando um conjunto de dados de 10 mil observações, treine um modelo de regressão polinomial com grau $p=1, ..., 15$. Estime o risco preditivo do melhor modelo. Construa um gráfico do melhor modelo ajustando aos dados de teste, i.e., $y$ versus $\\hat{y}$ do conjunto de teste.\\\n\n`Resposta:`\n\n```{r, warning=FALSE}\nrm(list=ls())\n# Carregando as bibliotecas\nlibrary(tidymodels)\nlibrary(ggplot2)\nlibrary(tibble)\nlibrary(rsample)\nlibrary(patchwork)\n\n# Modelo real que não conhecemos\nrandom_real <- function(n){\n  x <- runif(n = n, min = 0, max = 18)\n  # Regressão real\n  y <- 45 * tanh(x/1.9 - 7) + 57  + rnorm(n, 0, 2)\n\n  tibble(x = x, y = y)\n}\n\n# Função para treinar o modelo\ntreinar <- function(p, dados_treino){\n  # Criando uma regressao polinomial\n  lm(data = dados_treino, y ~ poly(x, degree = p, raw = TRUE))\n}\n\n# Função para testar o modelo\nteste <- function(modelo, dados_teste){\n  # Calculando o erro quadrático médio\n  dados_teste %>%\n    mutate(\n      y_hat = predict(modelo, newdata = dados_teste) # Aqui calculo y chapeu\n    ) %>%\n    summarise(\n      eqm = mean((y - y_hat)^2)\n    )\n}\n\n# Função para avaliar o erro quadrático médio\navaliacao_eqm <- function(p, dados_treino, dados_teste){\n\n  # Treinando o modelo\n  ajuste <- treinar(p, dados_treino)\n\n  # Calculando o erro quadrático médio\n  eqm <- teste(ajuste, dados_teste)\n\n  list(ajuste = ajuste, eqm = as.numeric(eqm[1,1]))\n}\n```\n\n```{r, warning=FALSE}\n# Fixando semente\nset.seed(0)\n\n# Gerando a base total de dados com 10000 observações\ndados <- random_real(n = 10000)\n\n# Realizando o Hold-out\ndados_divididos <- rsample::initial_split(dados, prop = 0.8, strata = y)\ndados_treino <- rsample::training(dados_divididos)\ndados_teste <- rsample::testing(dados_divididos)\ngrau_maximo <- 15\n\n# Avaliando o erro quadrático médio para cada grau de polinômio\nvalores <-\n  purrr::map_dbl(\n    .x = 1L:grau_maximo,\n    .f = \\(p) avaliacao_eqm(p = p, dados_treino = dados_treino, dados_teste = dados_teste)$eqm\n  )\n\n# Melhor grau de polinômio\nmelhor_p <- which.min(valores)\nmelhor_p\n```\n\n```{r, warning=FALSE}\n# Ajustando a regressão verdadeira com melhor_p sobre os dados\najuste <- treinar(p = melhor_p, dados_treino = dados_teste)\n\n# Visualizando os dados e a regressão real\np <- ggplot(data = dados_teste, aes(x = x, y = y)) +\n  geom_point() +\n  theme_minimal() +\n  ggtitle(\"Dados reais\") +\n  stat_function(fun = function(x) 45 * tanh(x/1.9 - 7) + 57, col = \"red\", linewidth = 1.2)\n\n# Visualizando o ajuste\np_ajuste <-\n  p +\n  geom_function(fun = function(x) predict(ajuste, newdata = tibble(x = x)), col = \"blue\", linewidth = 1.2) +\n  ggtitle(\"Ajuste\") +\n  labs(x = \"x\", y = \"y\")\n\n# Visualizando os EQM's\np_eqm <-\n  tibble(p = 1L:grau_maximo, eqm = valores) %>%\n  ggplot(aes(x = p, y = eqm)) +\n  geom_line(linetype = \"dotted\", linewidth = 1) +\n  annotate(\"point\", x = melhor_p, y = valores[melhor_p], col = \"red\", size = 4, alpha = 0.7) +\n  theme_minimal() +\n  ggtitle(\"EQM\") +\n  labs(x = \"p\", y = \"EQM\") +\n  scale_y_log10()\n\np + p_ajuste + p_eqm\n\n```\n\nNota-se que o melhor modelo de regressão polinomial é o de grau 14. O gráfico acima mostra a regressão real (em vermelho) e o ajuste do modelo de regressão polinomial de grau 14 (em azul) sobre os dados de teste. Além disso, o gráfico de EQM mostra que o modelo de grau 14 é o que apresenta menor Erro Quadrático Médio.\\\n","srcMarkdownNoYaml":"\n\n# Questão 1:\n\nDisserte sobre o processo de treinamento de modelo de regressão em aprendizagem de máquina. Explique cada um dos passos considerando a imagem que segue:\\\n![](C:/Users/luiza/OneDrive/Documentos/JOANA/ESTATÍSTICA/2024.1/Aprendizagem de Máquina/AM/Prova1/dados/imagem_questao1_AM_p1.png){width=\"70%\"}\\\nNão esqueça de explicar:\\\n1. O que é a validação cruzada e qual a diferença entre o *leave-one-out* e o *k-fold cross-validation*;\\\n2. O que é o risco preditivo do modelo e qual seu estimador;\\\n3. A importância de se ter uma base de dados de teste para avaliação final do modelo.\\\n\n`Resposta:` No processo de treinamento de um modelo de regressão em aprendizagem de máquina, primeimeiramente fazemos o *data spliting* dos dados, ou seja, a divisão dos dados que usualmente é dividida em treino, validação e teste, onde no conjunto de treino realizamos o ajuste do modelo que melhor se adaptou aos dados, no conjunto de validação fazemos a tunagem de hiperparâmetros do modelo, e no conjunto de teste é onde avaliamos o desempenho do modelo final escolhido por meio do risco preditivo. A validação cruzada consiste na divisão dos dados em treino e validação, em que no *leave-one-out cross validation* a cada iteração tiramos de fora uma única observação para teste e treinamos o modelo com as observações que ficaram, assim consequentemente, iremos ter $n$ modelos ajustados, em que $n$ é o número de observações total na base de dados. Já no *k-fold cross validation* iremos ter $k$ modelos finais ajustados, em que $k$ é o número de lotes, onde a cada iteração um determinado lote será utilizado para teste e o restante das observações serão usadas para treinar o modelo. O risco preditivo avalia o desempenho do modelo ajustado, no qual o Erro Quadrático Médio (EQM) geralmente é utilizado como medida para avaliar este desempenho, onde o EQM é a média do quadrado dos erros entre os valores observados e os valores preditos pelo modelo. É importante termos uma base de dados somente de teste para avaliação do modelo final, pois é nela que verificamos a capacidade de generalização do modelo.\\\n\n# Questão 2:\n\nConsidere o modelo de regressão real definido pela equação abaixo:\\\n$$r(x) = 2.76 + 0.5x_1 - 0.75x_2 + 0.5x_3 - 0.75x_4 + x_5 + \\sum_{i=6}^{30} 0x_i + \\epsilon,$$\\\nem que $\\epsilon \\sim N(0,0.5^2)$ e $x_i \\sim N(0,1)$, $\\forall{i} = 1, ..., 30$. Treine um modelo de regressão linear múltipla e estime o risco preditivo do modelo.\\\n\n**Dicas:**\\\n1. Considere uma base de dados com $n=1000$ observações e $31$ colunas;\\\n2. Note que $X$ será uma matriz de *features* (recursos/covariáveis) com $31$ colunas, sendo a primeira coluna composta por $1’s$ (por conta do intercepto) e as demais colunas compostas por valores aleatórios de uma distribuição normal padrão, conforme mencionado anteriormente, i.e., $x_i \\sim N(0,1), \\forall{i}$;\\\n3. Note que não há hiperparâmetros a serem ajustados, diferentemente da regressão polinomial que vimos em sala de aula;\\\n4. Não havendo hiperparâmetros, você precisa apenas dividir a base de dados entre treino e teste, isto é, realizar o *hold-out*;\\\n5. Ajuste o modelo na base de dados considerando o conjunto de treino;\\\n6. Avalie o modelo na base de teste.\\\n\n`Resposta:`\n\n```{r, warning=FALSE}\nrm(list=ls())\nlibrary(tidymodels)\n\ntidymodels_prefer()\n\nn = 1000\n\n# Modelo real que não conhecemos\nrandom_real <- function(n){\n  x <- rnorm(n, 0, 1)\n    runif(n, 8, 18)\n  y <- 2.76 + 0.5*x1 - 0.75*x2 + 0.5*x3 - 0.75*x4  + x5 + sum(xi) + rnorm(n, 0, 0.5)\n  tibble(x = x, y = y)\n}\n```\n\n# Questão 3:\n\nConsidere o modelo de regressão real dado por: $$r(x) = 1.6 + 5\\sin(x) - 8x^2 + \\epsilon,$$\\\nem que $x \\sim U(0,20)$ e $\\epsilon \\sim N(0,1)$ (normal padrão). Treine modelos de regressão polinomial com o grau do polinômio $p=1,2,3$ e estime o risco preditivo de cada um dos modelos.\\\n\n**Dicas:**\\\n1. Considere $n = 10000$ observações;\\\n2. Não é necessário fazer fazer *cross-validation*;\\\n3. Apenas considere treino e teste;\\\n4. Ajuste cada um dos modelos no treino e estime o risco preditivo do modelo de cada um dos modelos no conjunto de teste.\\\n\nInterprete o resultado obtido.\n\n![](C:/Users/luiza/OneDrive/Documentos/JOANA/ESTATÍSTICA/2024.1/Aprendizagem de Máquina/AM/Prova1/dados/imagem_questao3_AM_p1.png){width=\"70%\"}\\\n\n`Resposta:`\n\n```{r, warning=FALSE, message=FALSE}\nrm(list=ls())\n# Carregando as bibliotecas\nlibrary(tidymodels)\nlibrary(ggplot2)\nlibrary(tibble)\nlibrary(rsample)\nlibrary(patchwork)\nlibrary(tidyverse)\n\ntidymodels_prefer()\n\n# Modelo real que não conhecemos\nrandom_real <- function(n){\n  x <- runif(n = n, min = 0, max = 20)\n  # Essa é a regressão real\n  y <- 1.6 + 5*sin(x) - 8*(x^2) + rnorm(n, mean = 0, sd = 1)\n\n  tibble(x = x, y = y)\n}\n\n# Funções para treinar\ntreinar <- function(p, dados_treino){\n  # Criando uma regressao polinomial\n  lm(data = dados_treino, y ~ poly(x, degree = p, raw = TRUE))\n}\n\n# Função para testar\nteste <- function(modelo, dados_teste){\n  # Calculando o erro quadrático médio\n  dados_teste %>%\n    mutate(\n      y_hat = predict(modelo, newdata = dados_teste) # Aqui calculo y chapeu\n    ) %>%\n    summarise(\n      eqm = mean((y - y_hat)^2)\n    )\n}\n\n# Função para avaliar o modelo\navaliacao_eqm <- function(p, dados_treino, dados_teste){\n\n  # Treinando o modelo\n  ajuste <- treinar(p, dados_treino)\n\n  # Calculando o erro quadrático médio\n  eqm <- teste(ajuste, dados_teste)\n\n  list(ajuste = ajuste, eqm = as.numeric(eqm[1,1]))\n}\n```\n\n```{r, warning=FALSE}\n# Fixando semente\nset.seed(0)\n\n# Gerando a base total de dados com 10000 observações\ndados <- random_real(n = 10000)\n\n#  Realizando o Hold-out\ndados_divididos <- rsample::initial_split(dados, prop = 0.8, strata = y)\ndados_treino <- rsample::training(dados_divididos)\ndados_teste <- rsample::testing(dados_divididos)\ngrau_maximo <- 3\n\n# Avaliando o erro quadrático médio para cada grau\nvec_eqm <-\n  purrr::map_dbl(\n    .x = 1L:grau_maximo,\n    .f = \\(p) avaliacao_eqm(p = p, dados_treino = dados_treino, dados_teste = dados_teste)$eqm\n  )\n```\n\n```{r, warning=FALSE}\n# Tabela com os EQM's e seus respectivos graus de polinômio\ndados_eqm <- tibble(p = 1L:grau_maximo, eqm = vec_eqm)\ndados_eqm\n```\n\n```{r, warning=FALSE}\n# Melhor grau do polinômio que tem o menor EQM\nmelhor_p <- which.min(vec_eqm)\nmelhor_p\n```\n\n```{r, warning=FALSE}\n# Ajustando a regressão verdadeira com grau 1 sobre os dados\najuste1 <- treinar(p = 1, dados_treino = dados_teste)\najuste1\n```\n\n```{r, warning=FALSE}\n# Ajustando a regressão verdadeira com grau 2 sobre os dados\najuste2 <- treinar(p = 2, dados_treino = dados_teste)\najuste2\n```\n\n```{r, warning=FALSE}\n# Ajustando a regressão verdadeira com grau 3 sobre os dados\najuste3 <- treinar(p = 3, dados_treino = dados_teste)\najuste3\n```\n\nObserva-se que o melhor o modelo de regressão polinomial é o de grau 3, pois apresentou menor erro quadrático médio.\\\n\n\n# Questão 4:\n\nConsidere a base de dados referente à vendas de sorvetes. A base de dados contém as seguintes variáveis:\\\n1. `Temperatura:` temperatura média do dia;\\\n2. `Vendas:` quantidade de sorvetes vendidos no dia.\\\n\n**Download:** Para baixar os dados, acesse o [link](https://www.kaggle.com/datasets/mirajdeepbhandari/polynomial-regression?select=Ice_cream+selling+data.csv) e clique em \"Download\", no canto superior direito.\\\n\nEstamos interessados em estimar as vendas de sorvetes dado a temperatura. Dessa forma, considere o número de vendas como sendo o *label* (variável $y$) e as temperaturas como sendo as *features* (variáveis $x$).\\\n\nConsiderando a base de dados fornecida, treine um modelo de regressão polinomial com grau $p = 1,2,3,4,5$ e estime o risco preditivo do modelo selecionado. Além disso, construa um gráfico do modelo selecionado ajustado aos dados.\\\n\n**Dicas:**\\\n1. Considere utilizar um esquema de validação cruzada para selecionar o melhor hiperparâmetro;\\\n2. Com o grau de polinômio escolhido, treine o modelo na base de dados de treino e avalie o risco desse modelo no conjunto de teste;\\\n3. Considere uma divisão inicial *(hold-out)* na proporção $80\\%$ (treino) e $20\\%$ para teste.\\\n\n`Resposta:`\n\n```{r, warning=FALSE}\nrm(list=ls())\n# Carregando os pacotes\nlibrary(tidymodels)\nlibrary(ggplot2)\nlibrary(tibble)\nlibrary(rsample)\nlibrary(patchwork)\nlibrary(tidyverse)\nlibrary(corrr)\n\ntidymodels::tidymodels_prefer()\n\n# Carregando a base de dados\ndados <- read.csv(\"~/JOANA/ESTATÍSTICA/2024.1/Aprendizagem de Máquina/AM/Prova1/dados/Ice_cream.csv\", sep = \",\",\n                  col.names = c(\"temperatura\",\"vendas\"))\n\n# Renomeando as variáveis\ndados <- dados %>% dplyr::rename(x = temperatura, y = vendas)\n\n# Fixando a semente\nset.seed(0)\n\n# Realizadon hold-out\ndados_split <- rsample::initial_split(dados, prop = 0.8, strata = \"y\")\ntreino <- rsample::training(dados_split)\nteste <- rsample::testing(dados_split)\n\n# Fazendo validação cruzada\ncv <- vfold_cv(treino, v = 5)\n\n# Definindo o modelo\nmodelo <-\n  parsnip::linear_reg() %>%\n  parsnip::set_engine(\"lm\") %>%\n  parsnip::set_mode(\"regression\")\n\n\n# Definindo receita\nreceita <-\n  recipe(y ~ ., data = treino) %>%\n  recipes::step_poly(\n      all_numeric_predictors(),\n      degree = tune(\"p\"),\n      options = list(raw = TRUE)\n    )\n\n# Validacação cruzada\ncv <- vfold_cv(treino, v = 5)\n\n# Criando o workflow\nwf <-\n  workflow() %>%\n  add_recipe(receita) %>%\n  add_model(modelo)\n\n# Extraindo hiperparametros do modelo\nparametros <-\n  wf %>%\n  extract_parameter_set_dials() %>% # Extraindo os hiperparâmetros do modelo\n  extract_parameter_dials(\"p\") %>%\n  range_set(range = c(1, 5)) %>%\n  parameters()\n\nparametros$id <- \"p\"\n\n# Tunando o modelo\ntunagem <- tune_grid(\n  wf,\n  resamples = cv,\n  grid = tibble(p = 1:5), # Parâmetros que desejamos que ele teste\n  metrics = metric_set(rmse)\n)\n\n# Coletando as métricas e o melhor grau\ncollect_metrics(tunagem)\n```\n\n\n```{r, warning=FALSE}\n# Visualizando o melhor grau segundo a métrica RMSE\nshow_best(tunagem, n = 1, metric = \"rmse\")\n```\n\n\n```{r, warning=FALSE}\n# Selecionado o melhor \"p\"\nmelhor_p <- select_best(tunagem, metric = \"rmse\")\nmelhor_p\n```\nO melhor grau de polinômio é 2, segundo a métrica RMSE.\\\n\n\n```{r, warning=FALSE}\n# Finalizando\nwf <-\n  wf %>%\n  finalize_workflow(melhor_p)\n\n# Realizando o ajuste final do modelo\najuste <- last_fit(wf, dados_split, metrics = metric_set(rmse))\n\n# Olhando o desempenho no teste\ncollect_metrics(ajuste)\n```\n\n\n```{r, warning=FALSE, message= FALSE}\nreal_vs_estimado <- collect_predictions(ajuste)\n\nreal_vs_estimado %>%\n  ggplot(aes(x = .pred, y = y)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"tomato\") +\n  labs(\n    title = \"Real vs Estimado\",\n    subtitle = \"Base de teste\",\n    x = \"Previsões\",\n    y = \"Observações\"\n  )\n```\n\n\n```{r, warning=FALSE}\n# Prevendo\ndados_qualquer <- sample_n(dados, 10) # Seleciona 10 linhas quaisquer de dados.\nwf_modelo <- extract_workflow(ajuste)\nvalores_previstos <- predict(wf_modelo, new_data = dados_qualquer)\n\n# Visualizando lado a lado, y e valores previstos\ndplyr::bind_cols(dados_qualquer, valores_previstos)\n```\n\n\n```{r, warning=FALSE}\n# Prevendo o número de vendas de sorvetes em uma temperatura de 3 graus celsius\npredict(wf_modelo, new_data = tibble(x = 3))\n\n```\n\nEstima-se que o número de vendas de sorvetes em uma temperatura de 3 graus celsius é de aproximadamente 16 unidades.\\\n\n\n# Questão 5:\n\nConsidere o modelo de regressão real dado por: $$r(x) = 45 \\times tanh\\left(\\frac{x}{1.9} - 7\\right) + 57 + \\epsilon,$$\\\nem que $x$ são observações de uma variável aleatória $X \\sim U(0,18)$ e $\\epsilon \\sim N(0,4)$. Considerando um conjunto de dados de 10 mil observações, treine um modelo de regressão polinomial com grau $p=1, ..., 15$. Estime o risco preditivo do melhor modelo. Construa um gráfico do melhor modelo ajustando aos dados de teste, i.e., $y$ versus $\\hat{y}$ do conjunto de teste.\\\n\n`Resposta:`\n\n```{r, warning=FALSE}\nrm(list=ls())\n# Carregando as bibliotecas\nlibrary(tidymodels)\nlibrary(ggplot2)\nlibrary(tibble)\nlibrary(rsample)\nlibrary(patchwork)\n\n# Modelo real que não conhecemos\nrandom_real <- function(n){\n  x <- runif(n = n, min = 0, max = 18)\n  # Regressão real\n  y <- 45 * tanh(x/1.9 - 7) + 57  + rnorm(n, 0, 2)\n\n  tibble(x = x, y = y)\n}\n\n# Função para treinar o modelo\ntreinar <- function(p, dados_treino){\n  # Criando uma regressao polinomial\n  lm(data = dados_treino, y ~ poly(x, degree = p, raw = TRUE))\n}\n\n# Função para testar o modelo\nteste <- function(modelo, dados_teste){\n  # Calculando o erro quadrático médio\n  dados_teste %>%\n    mutate(\n      y_hat = predict(modelo, newdata = dados_teste) # Aqui calculo y chapeu\n    ) %>%\n    summarise(\n      eqm = mean((y - y_hat)^2)\n    )\n}\n\n# Função para avaliar o erro quadrático médio\navaliacao_eqm <- function(p, dados_treino, dados_teste){\n\n  # Treinando o modelo\n  ajuste <- treinar(p, dados_treino)\n\n  # Calculando o erro quadrático médio\n  eqm <- teste(ajuste, dados_teste)\n\n  list(ajuste = ajuste, eqm = as.numeric(eqm[1,1]))\n}\n```\n\n```{r, warning=FALSE}\n# Fixando semente\nset.seed(0)\n\n# Gerando a base total de dados com 10000 observações\ndados <- random_real(n = 10000)\n\n# Realizando o Hold-out\ndados_divididos <- rsample::initial_split(dados, prop = 0.8, strata = y)\ndados_treino <- rsample::training(dados_divididos)\ndados_teste <- rsample::testing(dados_divididos)\ngrau_maximo <- 15\n\n# Avaliando o erro quadrático médio para cada grau de polinômio\nvalores <-\n  purrr::map_dbl(\n    .x = 1L:grau_maximo,\n    .f = \\(p) avaliacao_eqm(p = p, dados_treino = dados_treino, dados_teste = dados_teste)$eqm\n  )\n\n# Melhor grau de polinômio\nmelhor_p <- which.min(valores)\nmelhor_p\n```\n\n```{r, warning=FALSE}\n# Ajustando a regressão verdadeira com melhor_p sobre os dados\najuste <- treinar(p = melhor_p, dados_treino = dados_teste)\n\n# Visualizando os dados e a regressão real\np <- ggplot(data = dados_teste, aes(x = x, y = y)) +\n  geom_point() +\n  theme_minimal() +\n  ggtitle(\"Dados reais\") +\n  stat_function(fun = function(x) 45 * tanh(x/1.9 - 7) + 57, col = \"red\", linewidth = 1.2)\n\n# Visualizando o ajuste\np_ajuste <-\n  p +\n  geom_function(fun = function(x) predict(ajuste, newdata = tibble(x = x)), col = \"blue\", linewidth = 1.2) +\n  ggtitle(\"Ajuste\") +\n  labs(x = \"x\", y = \"y\")\n\n# Visualizando os EQM's\np_eqm <-\n  tibble(p = 1L:grau_maximo, eqm = valores) %>%\n  ggplot(aes(x = p, y = eqm)) +\n  geom_line(linetype = \"dotted\", linewidth = 1) +\n  annotate(\"point\", x = melhor_p, y = valores[melhor_p], col = \"red\", size = 4, alpha = 0.7) +\n  theme_minimal() +\n  ggtitle(\"EQM\") +\n  labs(x = \"p\", y = \"EQM\") +\n  scale_y_log10()\n\np + p_ajuste + p_eqm\n\n```\n\nNota-se que o melhor modelo de regressão polinomial é o de grau 14. O gráfico acima mostra a regressão real (em vermelho) e o ajuste do modelo de regressão polinomial de grau 14 (em azul) sobre os dados de teste. Além disso, o gráfico de EQM mostra que o modelo de grau 14 é o que apresenta menor Erro Quadrático Médio.\\\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":1000,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"show","code-overflow":"scroll","code-link":true,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":true,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","self-contained":true,"highlight-style":"github","toc":true,"toc-depth":2,"number-sections":false,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.549","title":"Prova 1 - Aprendizagem de Máquina","author":"Joana D'arc Nunes da Silva, Matrícula: 20180078535","date":"last-modified","date-format":"DD MMM, YYYY","page-layout":"full","editor":"source","code-block-bg":true,"code-block-border-left":"#9400D3","toc-title":"Sumário","toc-location":"left","number-depth":3,"smooth-scroll":true},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}