{
  "hash": "58c7ca358169fd849831a29c6f3f3515",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Prova 1 - Aprendizagem de Máquina\"\nauthor: \"Joana D'arc Nunes da Silva, Matrícula: 20180078535\"\ndate: last-modified\ndate-format: \"DD MMM, YYYY\"\nformat:\n  html:\n    theme: lux\n    code-fold: show\n    code-tools: false\n    code-block-bg: true\n    code-block-border-left: \"#9400D3\"\n    highlight-style: github\n    code-link: true\n    toc: true\n    toc-title: Sumário\n    toc-location: left\n    toc-depth: 2\n    number-sections: false\n    number-depth: 3\n    smooth-scroll: true\n    link-external-newwindow: true\nfig-dpi: 1000\nself-contained: true\npage-layout: full\neditor: source\n---\n\n\n# Questão 1:\n\nDisserte sobre o processo de treinamento de modelo de regressão em aprendizagem de máquina. Explique cada um dos passos considerando a imagem que segue:\\\n![](C:/Users/luiza/OneDrive/Documentos/JOANA/ESTATÍSTICA/2024.1/Aprendizagem de Máquina/AM/Prova1/dados/imagem_questao1_AM_p1.png){width=\"70%\"}\\\nNão esqueça de explicar:\\\n1. O que é a validação cruzada e qual a diferença entre o *leave-one-out* e o *k-fold cross-validation*;\\\n2. O que é o risco preditivo do modelo e qual seu estimador;\\\n3. A importância de se ter uma base de dados de teste para avaliação final do modelo.\\\n\n`Resposta:` No processo de treinamento de um modelo de regressão em aprendizagem de máquina, primeimeiramente fazemos o *data spliting* dos dados, ou seja, a divisão dos dados que usualmente é dividida em treino, validação e teste, onde no conjunto de treino realizamos o ajuste do modelo que melhor se adaptou aos dados, no conjunto de validação fazemos a tunagem de hiperparâmetros do modelo, e no conjunto de teste é onde avaliamos o desempenho do modelo final escolhido por meio do risco preditivo. A validação cruzada consiste na divisão dos dados em treino e validação, em que no *leave-one-out cross validation* a cada iteração tiramos de fora uma única observação para teste e treinamos o modelo com as observações que ficaram, assim consequentemente, iremos ter $n$ modelos ajustados, em que $n$ é o número de observações total na base de dados. Já no *k-fold cross validation* iremos ter $k$ modelos finais ajustados, em que $k$ é o número de lotes, onde a cada iteração um determinado lote será utilizado para teste e o restante das observações serão usadas para treinar o modelo. O risco preditivo avalia o desempenho do modelo ajustado, no qual o Erro Quadrático Médio (EQM) geralmente é utilizado como medida para avaliar este desempenho, onde o EQM é a média do quadrado dos erros entre os valores observados e os valores preditos pelo modelo. É importante termos uma base de dados somente de teste para avaliação do modelo final, pois é nela que verificamos a capacidade de generalização do modelo.\\\n\n# Questão 2:\n\nConsidere o modelo de regressão real definido pela equação abaixo:\\\n$$r(x) = 2.76 + 0.5x_1 - 0.75x_2 + 0.5x_3 - 0.75x_4 + x_5 + \\sum_{i=6}^{30} 0x_i + \\epsilon,$$\\\nem que $\\epsilon \\sim N(0,0.5^2)$ e $x_i \\sim N(0,1)$, $\\forall{i} = 1, ..., 30$. Treine um modelo de regressão linear múltipla e estime o risco preditivo do modelo.\\\n\n**Dicas:**\\\n1. Considere uma base de dados com $n=1000$ observações e $31$ colunas;\\\n2. Note que $X$ será uma matriz de *features* (recursos/covariáveis) com $31$ colunas, sendo a primeira coluna composta por $1’s$ (por conta do intercepto) e as demais colunas compostas por valores aleatórios de uma distribuição normal padrão, conforme mencionado anteriormente, i.e., $x_i \\sim N(0,1), \\forall{i}$;\\\n3. Note que não há hiperparâmetros a serem ajustados, diferentemente da regressão polinomial que vimos em sala de aula;\\\n4. Não havendo hiperparâmetros, você precisa apenas dividir a base de dados entre treino e teste, isto é, realizar o *hold-out*;\\\n5. Ajuste o modelo na base de dados considerando o conjunto de treino;\\\n6. Avalie o modelo na base de teste.\\\n\n`Resposta:`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm(list=ls())\nlibrary(tidymodels)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n✔ broom        1.0.6     ✔ recipes      1.1.0\n✔ dials        1.3.0     ✔ rsample      1.2.1\n✔ dplyr        1.1.4     ✔ tibble       3.2.1\n✔ ggplot2      3.5.1     ✔ tidyr        1.3.1\n✔ infer        1.0.7     ✔ tune         1.2.1\n✔ modeldata    1.4.0     ✔ workflows    1.1.4\n✔ parsnip      1.2.1     ✔ workflowsets 1.1.0\n✔ purrr        1.0.2     ✔ yardstick    1.3.1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Learn how to get started at https://www.tidymodels.org/start/\n```\n\n\n:::\n\n```{.r .cell-code}\ntidymodels_prefer()\n\nn = 1000\n\n# Modelo real que não conhecemos\nrandom_real <- function(n){\n  x <- rnorm(n, 0, 1)\n    runif(n, 8, 18)\n  y <- 2.76 + 0.5*x1 - 0.75*x2 + 0.5*x3 - 0.75*x4  + x5 + sum(xi) + rnorm(n, 0, 0.5)\n  tibble(x = x, y = y)\n}\n```\n:::\n\n\n# Questão 3:\n\nConsidere o modelo de regressão real dado por: $$r(x) = 1.6 + 5\\sin(x) - 8x^2 + \\epsilon,$$\\\nem que $x \\sim U(0,20)$ e $\\epsilon \\sim N(0,1)$ (normal padrão). Treine modelos de regressão polinomial com o grau do polinômio $p=1,2,3$ e estime o risco preditivo de cada um dos modelos.\\\n\n**Dicas:**\\\n1. Considere $n = 10000$ observações;\\\n2. Não é necessário fazer fazer *cross-validation*;\\\n3. Apenas considere treino e teste;\\\n4. Ajuste cada um dos modelos no treino e estime o risco preditivo do modelo de cada um dos modelos no conjunto de teste.\\\n\nInterprete o resultado obtido.\n\n![](C:/Users/luiza/OneDrive/Documentos/JOANA/ESTATÍSTICA/2024.1/Aprendizagem de Máquina/AM/Prova1/dados/imagem_questao3_AM_p1.png){width=\"70%\"}\\\n\n`Resposta:`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm(list=ls())\n# Carregando as bibliotecas\nlibrary(tidymodels)\nlibrary(ggplot2)\nlibrary(tibble)\nlibrary(rsample)\nlibrary(patchwork)\nlibrary(tidyverse)\n\ntidymodels_prefer()\n\n# Modelo real que não conhecemos\nrandom_real <- function(n){\n  x <- runif(n = n, min = 0, max = 20)\n  # Essa é a regressão real\n  y <- 1.6 + 5*sin(x) - 8*(x^2) + rnorm(n, mean = 0, sd = 1)\n\n  tibble(x = x, y = y)\n}\n\n# Funções para treinar\ntreinar <- function(p, dados_treino){\n  # Criando uma regressao polinomial\n  lm(data = dados_treino, y ~ poly(x, degree = p, raw = TRUE))\n}\n\n# Função para testar\nteste <- function(modelo, dados_teste){\n  # Calculando o erro quadrático médio\n  dados_teste %>%\n    mutate(\n      y_hat = predict(modelo, newdata = dados_teste) # Aqui calculo y chapeu\n    ) %>%\n    summarise(\n      eqm = mean((y - y_hat)^2)\n    )\n}\n\n# Função para avaliar o modelo\navaliacao_eqm <- function(p, dados_treino, dados_teste){\n\n  # Treinando o modelo\n  ajuste <- treinar(p, dados_treino)\n\n  # Calculando o erro quadrático médio\n  eqm <- teste(ajuste, dados_teste)\n\n  list(ajuste = ajuste, eqm = as.numeric(eqm[1,1]))\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fixando semente\nset.seed(0)\n\n# Gerando a base total de dados com 10000 observações\ndados <- random_real(n = 10000)\n\n#  Realizando o Hold-out\ndados_divididos <- rsample::initial_split(dados, prop = 0.8, strata = y)\ndados_treino <- rsample::training(dados_divididos)\ndados_teste <- rsample::testing(dados_divididos)\ngrau_maximo <- 3\n\n# Avaliando o erro quadrático médio para cada grau\nvec_eqm <-\n  purrr::map_dbl(\n    .x = 1L:grau_maximo,\n    .f = \\(p) avaliacao_eqm(p = p, dados_treino = dados_treino, dados_teste = dados_teste)$eqm\n  )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Tabela com os EQM's e seus respectivos graus de polinômio\ndados_eqm <- tibble(p = 1L:grau_maximo, eqm = vec_eqm)\ndados_eqm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 2\n      p     eqm\n  <int>   <dbl>\n1     1 56140. \n2     2    12.5\n3     3    12.3\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Melhor grau do polinômio que tem o menor EQM\nmelhor_p <- which.min(vec_eqm)\nmelhor_p\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Ajustando a regressão verdadeira com grau 1 sobre os dados\najuste1 <- treinar(p = 1, dados_treino = dados_teste)\najuste1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ poly(x, degree = p, raw = TRUE), data = dados_treino)\n\nCoefficients:\n                    (Intercept)  poly(x, degree = p, raw = TRUE)  \n                          538.6                           -160.6  \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Ajustando a regressão verdadeira com grau 2 sobre os dados\najuste2 <- treinar(p = 2, dados_treino = dados_teste)\najuste2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ poly(x, degree = p, raw = TRUE), data = dados_treino)\n\nCoefficients:\n                     (Intercept)  poly(x, degree = p, raw = TRUE)1  \n                          4.1746                           -0.5012  \npoly(x, degree = p, raw = TRUE)2  \n                         -7.9806  \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Ajustando a regressão verdadeira com grau 3 sobre os dados\najuste3 <- treinar(p = 3, dados_treino = dados_teste)\najuste3\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ poly(x, degree = p, raw = TRUE), data = dados_treino)\n\nCoefficients:\n                     (Intercept)  poly(x, degree = p, raw = TRUE)1  \n                        5.265589                         -1.148003  \npoly(x, degree = p, raw = TRUE)2  poly(x, degree = p, raw = TRUE)3  \n                       -7.900008                         -0.002684  \n```\n\n\n:::\n:::\n\n\nObserva-se que o melhor o modelo de regressão polinomial é o de grau 3, pois apresentou menor erro quadrático médio.\\\n\n\n# Questão 4:\n\nConsidere a base de dados referente à vendas de sorvetes. A base de dados contém as seguintes variáveis:\\\n1. `Temperatura:` temperatura média do dia;\\\n2. `Vendas:` quantidade de sorvetes vendidos no dia.\\\n\n**Download:** Para baixar os dados, acesse o [link](https://www.kaggle.com/datasets/mirajdeepbhandari/polynomial-regression?select=Ice_cream+selling+data.csv) e clique em \"Download\", no canto superior direito.\\\n\nEstamos interessados em estimar as vendas de sorvetes dado a temperatura. Dessa forma, considere o número de vendas como sendo o *label* (variável $y$) e as temperaturas como sendo as *features* (variáveis $x$).\\\n\nConsiderando a base de dados fornecida, treine um modelo de regressão polinomial com grau $p = 1,2,3,4,5$ e estime o risco preditivo do modelo selecionado. Além disso, construa um gráfico do modelo selecionado ajustado aos dados.\\\n\n**Dicas:**\\\n1. Considere utilizar um esquema de validação cruzada para selecionar o melhor hiperparâmetro;\\\n2. Com o grau de polinômio escolhido, treine o modelo na base de dados de treino e avalie o risco desse modelo no conjunto de teste;\\\n3. Considere uma divisão inicial *(hold-out)* na proporção $80\\%$ (treino) e $20\\%$ para teste.\\\n\n`Resposta:`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm(list=ls())\n# Carregando os pacotes\nlibrary(tidymodels)\nlibrary(ggplot2)\nlibrary(tibble)\nlibrary(rsample)\nlibrary(patchwork)\nlibrary(tidyverse)\nlibrary(corrr)\n\ntidymodels::tidymodels_prefer()\n\n# Carregando a base de dados\ndados <- read.csv(\"~/JOANA/ESTATÍSTICA/2024.1/Aprendizagem de Máquina/AM/Prova1/dados/Ice_cream.csv\", sep = \",\",\n                  col.names = c(\"temperatura\",\"vendas\"))\n\n# Renomeando as variáveis\ndados <- dados %>% dplyr::rename(x = temperatura, y = vendas)\n\n# Fixando a semente\nset.seed(0)\n\n# Realizadon hold-out\ndados_split <- rsample::initial_split(dados, prop = 0.8, strata = \"y\")\ntreino <- rsample::training(dados_split)\nteste <- rsample::testing(dados_split)\n\n# Fazendo validação cruzada\ncv <- vfold_cv(treino, v = 5)\n\n# Definindo o modelo\nmodelo <-\n  parsnip::linear_reg() %>%\n  parsnip::set_engine(\"lm\") %>%\n  parsnip::set_mode(\"regression\")\n\n\n# Definindo receita\nreceita <-\n  recipe(y ~ ., data = treino) %>%\n  recipes::step_poly(\n      all_numeric_predictors(),\n      degree = tune(\"p\"),\n      options = list(raw = TRUE)\n    )\n\n# Validacação cruzada\ncv <- vfold_cv(treino, v = 5)\n\n# Criando o workflow\nwf <-\n  workflow() %>%\n  add_recipe(receita) %>%\n  add_model(modelo)\n\n# Extraindo hiperparametros do modelo\nparametros <-\n  wf %>%\n  extract_parameter_set_dials() %>% # Extraindo os hiperparâmetros do modelo\n  extract_parameter_dials(\"p\") %>%\n  range_set(range = c(1, 5)) %>%\n  parameters()\n\nparametros$id <- \"p\"\n\n# Tunando o modelo\ntunagem <- tune_grid(\n  wf,\n  resamples = cv,\n  grid = tibble(p = 1:5), # Parâmetros que desejamos que ele teste\n  metrics = metric_set(rmse)\n)\n\n# Coletando as métricas e o melhor grau\ncollect_metrics(tunagem)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 7\n      p .metric .estimator  mean     n std_err .config             \n  <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>               \n1     1 rmse    standard   12.7      5   1.41  Preprocessor1_Model1\n2     2 rmse    standard    3.66     5   0.407 Preprocessor2_Model1\n3     3 rmse    standard    4.51     5   1.35  Preprocessor3_Model1\n4     4 rmse    standard    4.20     5   1.53  Preprocessor4_Model1\n5     5 rmse    standard    5.02     5   2.35  Preprocessor5_Model1\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualizando o melhor grau segundo a métrica RMSE\nshow_best(tunagem, n = 1, metric = \"rmse\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 7\n      p .metric .estimator  mean     n std_err .config             \n  <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>               \n1     2 rmse    standard    3.66     5   0.407 Preprocessor2_Model1\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Selecionado o melhor \"p\"\nmelhor_p <- select_best(tunagem, metric = \"rmse\")\nmelhor_p\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 2\n      p .config             \n  <int> <chr>               \n1     2 Preprocessor2_Model1\n```\n\n\n:::\n:::\n\nO melhor grau de polinômio é 2, segundo a métrica RMSE.\\\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Finalizando\nwf <-\n  wf %>%\n  finalize_workflow(melhor_p)\n\n# Realizando o ajuste final do modelo\najuste <- last_fit(wf, dados_split, metrics = metric_set(rmse))\n\n# Olhando o desempenho no teste\ncollect_metrics(ajuste)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 4\n  .metric .estimator .estimate .config             \n  <chr>   <chr>          <dbl> <chr>               \n1 rmse    standard        3.08 Preprocessor1_Model1\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nreal_vs_estimado <- collect_predictions(ajuste)\n\nreal_vs_estimado %>%\n  ggplot(aes(x = .pred, y = y)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"tomato\") +\n  labs(\n    title = \"Real vs Estimado\",\n    subtitle = \"Base de teste\",\n    x = \"Previsões\",\n    y = \"Observações\"\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){width=7000}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Prevendo\ndados_qualquer <- sample_n(dados, 10) # Seleciona 10 linhas quaisquer de dados.\nwf_modelo <- extract_workflow(ajuste)\nvalores_previstos <- predict(wf_modelo, new_data = dados_qualquer)\n\n# Visualizando lado a lado, y e valores previstos\ndplyr::bind_cols(dados_qualquer, valores_previstos)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             x          y     .pred\n1  -2.28826400 18.1239912 14.495141\n2   3.70405744 17.8439565 24.299832\n3  -2.65228679 20.2796792 18.075166\n4   2.07510060  8.1707349  8.807715\n5  -0.03389529  0.8976032  2.976671\n6   1.24071162  1.2923608  4.581507\n7  -1.17312327  6.6891226  6.504845\n8   4.13086796 34.5307427 29.942415\n9   2.31859124  7.4120940 10.514634\n10  3.33593241 26.1047404 19.961191\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Prevendo o número de vendas de sorvetes em uma temperatura de 3 graus celsius\npredict(wf_modelo, new_data = tibble(x = 3))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 1\n  .pred\n  <dbl>\n1  16.4\n```\n\n\n:::\n:::\n\n\nEstima-se que o número de vendas de sorvetes em uma temperatura de 3 graus celsius é de aproximadamente 16 unidades.\\\n\n\n# Questão 5:\n\nConsidere o modelo de regressão real dado por: $$r(x) = 45 \\times tanh\\left(\\frac{x}{1.9} - 7\\right) + 57 + \\epsilon,$$\\\nem que $x$ são observações de uma variável aleatória $X \\sim U(0,18)$ e $\\epsilon \\sim N(0,4)$. Considerando um conjunto de dados de 10 mil observações, treine um modelo de regressão polinomial com grau $p=1, ..., 15$. Estime o risco preditivo do melhor modelo. Construa um gráfico do melhor modelo ajustando aos dados de teste, i.e., $y$ versus $\\hat{y}$ do conjunto de teste.\\\n\n`Resposta:`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm(list=ls())\n# Carregando as bibliotecas\nlibrary(tidymodels)\nlibrary(ggplot2)\nlibrary(tibble)\nlibrary(rsample)\nlibrary(patchwork)\n\n# Modelo real que não conhecemos\nrandom_real <- function(n){\n  x <- runif(n = n, min = 0, max = 18)\n  # Regressão real\n  y <- 45 * tanh(x/1.9 - 7) + 57  + rnorm(n, 0, 2)\n\n  tibble(x = x, y = y)\n}\n\n# Função para treinar o modelo\ntreinar <- function(p, dados_treino){\n  # Criando uma regressao polinomial\n  lm(data = dados_treino, y ~ poly(x, degree = p, raw = TRUE))\n}\n\n# Função para testar o modelo\nteste <- function(modelo, dados_teste){\n  # Calculando o erro quadrático médio\n  dados_teste %>%\n    mutate(\n      y_hat = predict(modelo, newdata = dados_teste) # Aqui calculo y chapeu\n    ) %>%\n    summarise(\n      eqm = mean((y - y_hat)^2)\n    )\n}\n\n# Função para avaliar o erro quadrático médio\navaliacao_eqm <- function(p, dados_treino, dados_teste){\n\n  # Treinando o modelo\n  ajuste <- treinar(p, dados_treino)\n\n  # Calculando o erro quadrático médio\n  eqm <- teste(ajuste, dados_teste)\n\n  list(ajuste = ajuste, eqm = as.numeric(eqm[1,1]))\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fixando semente\nset.seed(0)\n\n# Gerando a base total de dados com 10000 observações\ndados <- random_real(n = 10000)\n\n# Realizando o Hold-out\ndados_divididos <- rsample::initial_split(dados, prop = 0.8, strata = y)\ndados_treino <- rsample::training(dados_divididos)\ndados_teste <- rsample::testing(dados_divididos)\ngrau_maximo <- 15\n\n# Avaliando o erro quadrático médio para cada grau de polinômio\nvalores <-\n  purrr::map_dbl(\n    .x = 1L:grau_maximo,\n    .f = \\(p) avaliacao_eqm(p = p, dados_treino = dados_treino, dados_teste = dados_teste)$eqm\n  )\n\n# Melhor grau de polinômio\nmelhor_p <- which.min(valores)\nmelhor_p\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 14\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Ajustando a regressão verdadeira com melhor_p sobre os dados\najuste <- treinar(p = melhor_p, dados_treino = dados_teste)\n\n# Visualizando os dados e a regressão real\np <- ggplot(data = dados_teste, aes(x = x, y = y)) +\n  geom_point() +\n  theme_minimal() +\n  ggtitle(\"Dados reais\") +\n  stat_function(fun = function(x) 45 * tanh(x/1.9 - 7) + 57, col = \"red\", linewidth = 1.2)\n\n# Visualizando o ajuste\np_ajuste <-\n  p +\n  geom_function(fun = function(x) predict(ajuste, newdata = tibble(x = x)), col = \"blue\", linewidth = 1.2) +\n  ggtitle(\"Ajuste\") +\n  labs(x = \"x\", y = \"y\")\n\n# Visualizando os EQM's\np_eqm <-\n  tibble(p = 1L:grau_maximo, eqm = valores) %>%\n  ggplot(aes(x = p, y = eqm)) +\n  geom_line(linetype = \"dotted\", linewidth = 1) +\n  annotate(\"point\", x = melhor_p, y = valores[melhor_p], col = \"red\", size = 4, alpha = 0.7) +\n  theme_minimal() +\n  ggtitle(\"EQM\") +\n  labs(x = \"p\", y = \"EQM\") +\n  scale_y_log10()\n\np + p_ajuste + p_eqm\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-1.png){width=7000}\n:::\n:::\n\n\nNota-se que o melhor modelo de regressão polinomial é o de grau 14. O gráfico acima mostra a regressão real (em vermelho) e o ajuste do modelo de regressão polinomial de grau 14 (em azul) sobre os dados de teste. Além disso, o gráfico de EQM mostra que o modelo de grau 14 é o que apresenta menor Erro Quadrático Médio.\\\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}