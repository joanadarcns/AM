[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Prova 2 - Aprendizagem de Máquina",
    "section": "",
    "text": "Questão 1:\nCrie um problema de regressão simulado em que a variável target (variável resposta) depende de 5 variáveis preditoras, porém, a base de dados, com 5 mil observações possui outras 15 features que não são relevantes para a predição. A variável target deve ser gerada a partir de uma função linear das variáveis preditoras, em que você poderá definir os pesos dessas 5 primeiras e as outras 15 restantes deverão ter peso zero. Ajuste a regressão Lasso e Ridge usando 10-fold cross-validation e avalie o risco preditivo dos modelos. Quais os valores estimados dos coeficientes e qual modelo você escolheria para fazer previsões? Qual dos modelos gerou um vetor esparso dos coeficientes estimados?\n\nResposta:\n\n\nCode\nrm(list = ls())\n\n# Carregando pacotes \nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(tidymodels)\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.6     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n\n\nCode\nlibrary(tibble)\nlibrary(purrr)\nlibrary(ggplot2)\nlibrary(patchwork)\nlibrary(workflowsets)\nlibrary(yardstick)\nlibrary(glmnet)\n\n\nCarregando pacotes exigidos: Matrix\n\nAnexando pacote: 'Matrix'\n\nOs seguintes objetos são mascarados por 'package:tidyr':\n\n    expand, pack, unpack\n\nLoaded glmnet 4.1-8\n\n\nCode\n# Dando preferencias as funcoes do tidymodels \ntidymodels::tidymodels_prefer()\n\n# Setando a semente \nset.seed(0)\n\n# Função para gerar os dados \ngerando_dados &lt;- function(n = 5000L){\n  regressao &lt;- function(i){\n    x &lt;- rnorm(n = 5000L, 0, 1)\n    target &lt;- 7*x[1L] - 5*x[2L] + 2*x[3L] + 4*x[4L] + 9*x[5L] + rnorm(1L, 0, 0.5)\n    tibble(\n      y = target,\n      x1 = x[1L],\n      x2 = x[2L],\n      x3 = x[3L],\n      x4 = x[4L],\n      x5 = x[5L]\n    )\n  }\n  dados &lt;- purrr::map(.x = 1L:n, .f = regressao) %&gt;% \n    purrr::list_rbind()\n  \n  parte_esparsa &lt;- matrix(0, n, 15)\n  \n  dados &lt;- cbind(dados, parte_esparsa)\n  colnames(dados) &lt;- c(\"y\", paste0(\"x\", 1L:20L))\n  tibble::as_tibble(dados)\n}\n\ndados &lt;- gerando_dados()\n\n# Realizando o hold-out \ndados_split &lt;- rsample::initial_split(dados, prop = 0.8, strata = \"y\")\ntreino &lt;- rsample::training(dados_split)\nteste &lt;- rsample::testing(dados_split)\n\n# Setando o modelo (set engine) \nmodelo_ridge &lt;- \n  parsnip::linear_reg(penalty = tune::tune(), mixture = 0) %&gt;% \n  parsnip::set_mode(\"regression\") %&gt;% \n  parsnip::set_engine(\"glmnet\")\n\nmodelo_lasso &lt;- \n  parsnip::linear_reg(penalty = tune::tune(), mixture = 1) %&gt;% \n  parsnip::set_mode(\"regression\") %&gt;% \n  parsnip::set_engine(\"glmnet\")\n\n# Criando workflows \nall_wf &lt;- \n  workflowsets::workflow_set(\n    preproc = list(y ~ .),\n    models = list(ridge = modelo_ridge, lasso = modelo_lasso), \n    cross = TRUE\n  )\n\n# Validação cruzada \nset.seed(0)\ncv &lt;- rsample::vfold_cv(treino, v = 10L)\n\n# Setando a métrica \nmetrica &lt;- yardstick::metric_set(rmse)\n\n# Tunagem dos hiperparâmetros \ntunagem &lt;- \n  all_wf %&gt;% \n  workflowsets::workflow_map(\n    seed = 0, \n    verbose = TRUE,\n    resamples = cv,\n    grid = 50,\n    metrics = metrica\n  )\n\n\ni 1 of 2 tuning:     formula_ridge\n✔ 1 of 2 tuning:     formula_ridge (2.4s)\ni 2 of 2 tuning:     formula_lasso\n✔ 2 of 2 tuning:     formula_lasso (1.8s)\n\n\n\n\nCode\n# Rank dos melhores modelos \nmodelos_rank &lt;- tunagem %&gt;% workflowsets::rank_results() %&gt;% print()\n\n\n# A tibble: 100 × 9\n   wflow_id      .config    .metric  mean std_err     n preprocessor model  rank\n   &lt;chr&gt;         &lt;chr&gt;      &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n 1 formula_lasso Preproces… rmse    0.507 0.00564    10 formula      line…     1\n 2 formula_lasso Preproces… rmse    0.507 0.00564    10 formula      line…     2\n 3 formula_lasso Preproces… rmse    0.507 0.00564    10 formula      line…     3\n 4 formula_lasso Preproces… rmse    0.507 0.00564    10 formula      line…     4\n 5 formula_lasso Preproces… rmse    0.507 0.00564    10 formula      line…     5\n 6 formula_lasso Preproces… rmse    0.507 0.00564    10 formula      line…     6\n 7 formula_lasso Preproces… rmse    0.507 0.00564    10 formula      line…     7\n 8 formula_lasso Preproces… rmse    0.507 0.00564    10 formula      line…     8\n 9 formula_lasso Preproces… rmse    0.507 0.00564    10 formula      line…     9\n10 formula_lasso Preproces… rmse    0.507 0.00564    10 formula      line…    10\n# ℹ 90 more rows\n\n\n\n\nCode\n# Selecionando os melhores modelos \nmelhor_ridge &lt;- \n  tunagem %&gt;% \n  workflowsets::extract_workflow_set_result(\"formula_ridge\") %&gt;% \n  tune::select_best(metric = \"rmse\") \n\nmelhor_lasso &lt;- \n  tunagem %&gt;% \n  workflowsets::extract_workflow_set_result(\"formula_lasso\") %&gt;% \n  tune::select_best(metric =\"rmse\")\n\n# Finalizando os modelos \nfinalizando_ridge &lt;- \n  tunagem %&gt;% \n  workflowsets::extract_workflow(\"formula_ridge\") %&gt;% \n  tune::finalize_workflow(melhor_ridge) %&gt;% \n  tune::last_fit(split = dados_split)\n\nfinalizando_lasso &lt;- \n  tunagem %&gt;% \n  workflowsets::extract_workflow(\"formula_lasso\") %&gt;% \n  tune::finalize_workflow(melhor_lasso) %&gt;% \n  tune::last_fit(split = dados_split)\n\n# Visualizando as métricas do modelo Ridge\nfinalizando_ridge %&gt;% workflowsets::collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard       0.965 Preprocessor1_Model1\n2 rsq     standard       0.999 Preprocessor1_Model1\n\n\n\n\nCode\n# Visualizando as métricas do modelo Lasso\nfinalizando_lasso %&gt;% workflowsets::collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard       0.503 Preprocessor1_Model1\n2 rsq     standard       0.999 Preprocessor1_Model1\n\n\nAvaliando o risco preditivo dos modelos, nota-se que o modelo Lasso apresentou um Erro Quadrático Médio (EQM) de \\(0.503\\), enquanto o modelo Ridge apresentou um EQM de \\(0.965\\). Além disso, observa-se que ambos os modelos apresentaram um \\(R^{2}\\) de \\(0.999\\). Como o risco preditivo do modelo Lasso foi menor que o do modelo Ridge, então eu escolheria o modelo Lasso para fazer as previsões.\n\n\n\nCode\n# Visualizando predições do modelo Ridge\nfinalizando_ridge %&gt;% workflowsets::collect_predictions()\n\n\n# A tibble: 1,000 × 5\n     .pred id                .row       y .config             \n     &lt;dbl&gt; &lt;chr&gt;            &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n 1  15.3   train/test split    14  16.4   Preprocessor1_Model1\n 2  12.1   train/test split    15  12.7   Preprocessor1_Model1\n 3   0.246 train/test split    20   0.182 Preprocessor1_Model1\n 4 -16.4   train/test split    22 -17.9   Preprocessor1_Model1\n 5   9.21  train/test split    23  10.4   Preprocessor1_Model1\n 6   9.96  train/test split    29  10.2   Preprocessor1_Model1\n 7  11.2   train/test split    33  11.3   Preprocessor1_Model1\n 8   4.25  train/test split    36   4.71  Preprocessor1_Model1\n 9  -1.89  train/test split    38  -2.08  Preprocessor1_Model1\n10   5.75  train/test split    44   5.25  Preprocessor1_Model1\n# ℹ 990 more rows\n\n\n\n\nCode\n# Visualizando predições do modelo Lasso\nfinalizando_lasso %&gt;% workflowsets::collect_predictions()\n\n\n# A tibble: 1,000 × 5\n     .pred id                .row       y .config             \n     &lt;dbl&gt; &lt;chr&gt;            &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n 1  16.3   train/test split    14  16.4   Preprocessor1_Model1\n 2  12.8   train/test split    15  12.7   Preprocessor1_Model1\n 3   0.256 train/test split    20   0.182 Preprocessor1_Model1\n 4 -17.4   train/test split    22 -17.9   Preprocessor1_Model1\n 5   9.76  train/test split    23  10.4   Preprocessor1_Model1\n 6  10.6   train/test split    29  10.2   Preprocessor1_Model1\n 7  11.9   train/test split    33  11.3   Preprocessor1_Model1\n 8   4.52  train/test split    36   4.71  Preprocessor1_Model1\n 9  -1.99  train/test split    38  -2.08  Preprocessor1_Model1\n10   6.15  train/test split    44   5.25  Preprocessor1_Model1\n# ℹ 990 more rows\n\n\n\n\nCode\n# Extraindo o modelo Ridge\nmodelo_final_ridge &lt;- \n  finalizando_ridge %&gt;% \n  extract_fit_parsnip() \n\n# Extraindo o modelo Lasso\nmodelo_final_lasso &lt;- \n  finalizando_lasso %&gt;% \n  extract_fit_parsnip()\n\n\n\n\nCode\n# Visualizando os coeficientes estimados do modelo Ridge\ncoeficientes_ridge &lt;- modelo_final_ridge %&gt;% \n  tidy() %&gt;% \n  filter(term != \"(Intercept)\") %&gt;% print()\n\n\n# A tibble: 20 × 3\n   term  estimate  penalty\n   &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 x1        6.55 1.35e-10\n 2 x2       -4.70 1.35e-10\n 3 x3        1.87 1.35e-10\n 4 x4        3.77 1.35e-10\n 5 x5        8.43 1.35e-10\n 6 x6        0    1.35e-10\n 7 x7        0    1.35e-10\n 8 x8        0    1.35e-10\n 9 x9        0    1.35e-10\n10 x10       0    1.35e-10\n11 x11       0    1.35e-10\n12 x12       0    1.35e-10\n13 x13       0    1.35e-10\n14 x14       0    1.35e-10\n15 x15       0    1.35e-10\n16 x16       0    1.35e-10\n17 x17       0    1.35e-10\n18 x18       0    1.35e-10\n19 x19       0    1.35e-10\n20 x20       0    1.35e-10\n\n\n\n\nCode\n# Visualizando os coeficientes estimados do modelo Lasso\ncoeficientes_lasso &lt;- modelo_final_lasso %&gt;% \n  tidy() %&gt;% \n  filter(term != \"(Intercept)\") %&gt;% print()\n\n\n# A tibble: 20 × 3\n   term  estimate  penalty\n   &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 x1        6.95 1.35e-10\n 2 x2       -4.96 1.35e-10\n 3 x3        1.97 1.35e-10\n 4 x4        3.97 1.35e-10\n 5 x5        8.96 1.35e-10\n 6 x6        0    1.35e-10\n 7 x7        0    1.35e-10\n 8 x8        0    1.35e-10\n 9 x9        0    1.35e-10\n10 x10       0    1.35e-10\n11 x11       0    1.35e-10\n12 x12       0    1.35e-10\n13 x13       0    1.35e-10\n14 x14       0    1.35e-10\n15 x15       0    1.35e-10\n16 x16       0    1.35e-10\n17 x17       0    1.35e-10\n18 x18       0    1.35e-10\n19 x19       0    1.35e-10\n20 x20       0    1.35e-10\n\n\nO modelo Lasso gerou um vetor esparso de coeficientes estimados, pois assim como na penalização AIC é realizada a seleção de variáveis, consequentemente, alguns coeficientes são zerados, o mesmo não acontece com o modelo Ridge.\n\n\n\nCode\n# Fazendo previsões \ndados_novos &lt;- dados[sample(1:nrow(dados), 10), -1]\n\n# Fazendo previsões com o modelo Ridge\npredict(finalizando_ridge$.workflow[[1]], \n                           new_data = dados_novos)\n\n\n# A tibble: 10 × 1\n    .pred\n    &lt;dbl&gt;\n 1 -20.3 \n 2   5.21\n 3  15.4 \n 4   1.21\n 5 -17.6 \n 6 -29.0 \n 7   3.03\n 8  16.9 \n 9   8.68\n10  16.4 \n\n\n\n\nCode\n# Fazendo previsões com o modelo Lasso\npredict(finalizando_lasso$.workflow[[1]], \n                           new_data = dados_novos)\n\n\n# A tibble: 10 × 1\n    .pred\n    &lt;dbl&gt;\n 1 -21.5 \n 2   5.58\n 3  16.2 \n 4   1.33\n 5 -18.6 \n 6 -30.6 \n 7   3.25\n 8  17.9 \n 9   9.27\n10  17.4 \n\n\n\n\nCode\n# Adicionando as previsões com o modelo Ridge ao conjunto de dados original\naugment(finalizando_ridge$.workflow[[1]], \n                         new_data = dados_novos)\n\n\n# A tibble: 10 × 21\n    .pred     x1     x2     x3     x4     x5    x6    x7    x8    x9   x10   x11\n    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 -20.3  -1.25   0.763 -0.719 -1.25  -0.292     0     0     0     0     0     0\n 2   5.21  1.95   1.29  -1.12   0.403 -0.110     0     0     0     0     0     0\n 3  15.4   1.08  -1.06   0.714  1.70  -0.532     0     0     0     0     0     0\n 4   1.21 -1.02  -1.48  -0.677 -1.24   0.815     0     0     0     0     0     0\n 5 -17.6  -2.03   1.49  -1.40   0.406  0.458     0     0     0     0     0     0\n 6 -29.0  -1.75   1.53  -1.88  -0.506 -0.576     0     0     0     0     0     0\n 7   3.03 -0.988 -0.563 -0.308 -0.195  0.970     0     0     0     0     0     0\n 8  16.9   0.808  0.185  1.36   0.118  1.12      0     0     0     0     0     0\n 9   8.68 -0.148 -0.258  0.806 -1.27   1.39      0     0     0     0     0     0\n10  16.4   0.774  0.509  0.424  0.473  1.32      0     0     0     0     0     0\n# ℹ 9 more variables: x12 &lt;dbl&gt;, x13 &lt;dbl&gt;, x14 &lt;dbl&gt;, x15 &lt;dbl&gt;, x16 &lt;dbl&gt;,\n#   x17 &lt;dbl&gt;, x18 &lt;dbl&gt;, x19 &lt;dbl&gt;, x20 &lt;dbl&gt;\n\n\n\n\nCode\n# Adicionando as previsões com o modelo Lasso ao conjunto de dados original\naugment(finalizando_lasso$.workflow[[1]], \n                         new_data = dados_novos)\n\n\n# A tibble: 10 × 21\n    .pred     x1     x2     x3     x4     x5    x6    x7    x8    x9   x10   x11\n    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 -21.5  -1.25   0.763 -0.719 -1.25  -0.292     0     0     0     0     0     0\n 2   5.58  1.95   1.29  -1.12   0.403 -0.110     0     0     0     0     0     0\n 3  16.2   1.08  -1.06   0.714  1.70  -0.532     0     0     0     0     0     0\n 4   1.33 -1.02  -1.48  -0.677 -1.24   0.815     0     0     0     0     0     0\n 5 -18.6  -2.03   1.49  -1.40   0.406  0.458     0     0     0     0     0     0\n 6 -30.6  -1.75   1.53  -1.88  -0.506 -0.576     0     0     0     0     0     0\n 7   3.25 -0.988 -0.563 -0.308 -0.195  0.970     0     0     0     0     0     0\n 8  17.9   0.808  0.185  1.36   0.118  1.12      0     0     0     0     0     0\n 9   9.27 -0.148 -0.258  0.806 -1.27   1.39      0     0     0     0     0     0\n10  17.4   0.774  0.509  0.424  0.473  1.32      0     0     0     0     0     0\n# ℹ 9 more variables: x12 &lt;dbl&gt;, x13 &lt;dbl&gt;, x14 &lt;dbl&gt;, x15 &lt;dbl&gt;, x16 &lt;dbl&gt;,\n#   x17 &lt;dbl&gt;, x18 &lt;dbl&gt;, x19 &lt;dbl&gt;, x20 &lt;dbl&gt;\n\n\n\n\nQuestão 2:\nConsidere o melhor modelo da questão anterior, e compare-o com a regressão Elastic Net. Faça uma comparação justa dos modelos, utilizando workflow_set e workflow_map. Avalie o risco preditivo dos modelos e compare os coeficientes estimados. Qual dos modelos você escolheria para fazer previsões? Explique!\n\nResposta:\nComo o melhor modelo na questão anterior foi o modelo Lasso, então irei compará-lo com o modelo Elastic Net.\n\n\n\nCode\nrm(list = ls())\n\n# Carregando pacotes \nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(tibble)\nlibrary(purrr)\nlibrary(ggplot2)\nlibrary(patchwork)\nlibrary(workflowsets)\nlibrary(yardstick)\nlibrary(glmnet)\n\n# Dando preferencias as funcoes do tidymodels \ntidymodels::tidymodels_prefer()\n\n# Setando a semente \nset.seed(0)\n\n# Função para gerar os dados \ngerando_dados &lt;- function(n = 5000L){\n  regressao &lt;- function(i){\n    x &lt;- rnorm(n = 5000L, 0, 1)\n    target &lt;- 7*x[1L] - 5*x[2L] + 2*x[3L] + 4*x[4L] + 9*x[5L] + rnorm(1L, 0, 0.5)\n    tibble(\n      y = target,\n      x1 = x[1L],\n      x2 = x[2L],\n      x3 = x[3L],\n      x4 = x[4L],\n      x5 = x[5L]\n    )\n  }\n  dados &lt;- purrr::map(.x = 1L:n, .f = regressao) %&gt;% \n    purrr::list_rbind()\n  \n  parte_esparsa &lt;- matrix(0, n, 15)\n  \n  dados &lt;- cbind(dados, parte_esparsa)\n  colnames(dados) &lt;- c(\"y\", paste0(\"x\", 1L:20L))\n  tibble::as_tibble(dados)\n}\n\ndados &lt;- gerando_dados()\n\n# Realizando o hold-out \ndados_split &lt;- rsample::initial_split(dados, prop = 0.8, strata = \"y\")\ntreino &lt;- rsample::training(dados_split)\nteste &lt;- rsample::testing(dados_split)\n\n# Setando o modelo (set engine) \nmodelo_lasso &lt;- \n  parsnip::linear_reg(penalty = tune::tune(), mixture = 1) %&gt;% \n  parsnip::set_mode(\"regression\") %&gt;% \n  parsnip::set_engine(\"glmnet\")\n\nmodelo_elastic &lt;- \n  parsnip::linear_reg(penalty = tune::tune(), mixture = tune::tune()) %&gt;% \n  parsnip::set_mode(\"regression\") %&gt;% \n  parsnip::set_engine(\"glmnet\")\n\n# Criando workflows \nall_wf &lt;- \n  workflowsets::workflow_set(\n    preproc = list(y ~ .),\n    models = list(lasso = modelo_lasso, elastic = modelo_elastic), \n    cross = TRUE\n  )\n\n# Validação cruzada \nset.seed(0)\ncv &lt;- rsample::vfold_cv(treino, v = 10L)\n\n# Setando a métrica \nmetrica &lt;- yardstick::metric_set(rmse)\n\n# Tunagem dos hiperparâmetros \ntunagem &lt;- \n  all_wf %&gt;% \n  workflowsets::workflow_map(\n    seed = 0, \n    verbose = TRUE,\n    resamples = cv,\n    grid = 50,\n    metrics = metrica\n  )\n\n\ni 1 of 2 tuning:     formula_lasso\n\n\n✔ 1 of 2 tuning:     formula_lasso (1.7s)\n\n\ni 2 of 2 tuning:     formula_elastic\n\n\n✔ 2 of 2 tuning:     formula_elastic (39.9s)\n\n\n\n\nCode\n# Rank dos melhores modelos \nmodelos_rank &lt;- tunagem %&gt;% workflowsets::rank_results() %&gt;% print()\n\n\n# A tibble: 100 × 9\n   wflow_id        .config  .metric  mean std_err     n preprocessor model  rank\n   &lt;chr&gt;           &lt;chr&gt;    &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n 1 formula_elastic Preproc… rmse    0.506 0.00572    10 formula      line…     1\n 2 formula_elastic Preproc… rmse    0.506 0.00570    10 formula      line…     2\n 3 formula_elastic Preproc… rmse    0.506 0.00566    10 formula      line…     3\n 4 formula_elastic Preproc… rmse    0.506 0.00570    10 formula      line…     4\n 5 formula_elastic Preproc… rmse    0.506 0.00568    10 formula      line…     5\n 6 formula_elastic Preproc… rmse    0.506 0.00576    10 formula      line…     6\n 7 formula_elastic Preproc… rmse    0.506 0.00565    10 formula      line…     7\n 8 formula_elastic Preproc… rmse    0.506 0.00580    10 formula      line…     8\n 9 formula_elastic Preproc… rmse    0.506 0.00574    10 formula      line…     9\n10 formula_elastic Preproc… rmse    0.507 0.00566    10 formula      line…    10\n# ℹ 90 more rows\n\n\n\n\nCode\n# Selecionando os melhores modelos \nmelhor_lasso &lt;- \n  tunagem %&gt;% \n  workflowsets::extract_workflow_set_result(\"formula_lasso\") %&gt;% \n  tune::select_best(metric =\"rmse\")\n\nmelhor_elastic &lt;- \n  tunagem %&gt;% \n  workflowsets::extract_workflow_set_result(\"formula_elastic\") %&gt;% \n  tune::select_best(metric = \"rmse\")\n\n# Finalizando os modelos \nfinalizando_lasso &lt;- \n  tunagem %&gt;% \n  workflowsets::extract_workflow(\"formula_lasso\") %&gt;% \n  tune::finalize_workflow(melhor_lasso) %&gt;% \n  tune::last_fit(split = dados_split)\n\nfinalizando_elastic &lt;- \n  tunagem %&gt;% \n  workflowsets::extract_workflow(\"formula_elastic\") %&gt;% \n  tune::finalize_workflow(melhor_elastic) %&gt;% \n  tune::last_fit(split = dados_split)\n\n## Visualizando as métricas do modelo Lasso\nfinalizando_lasso %&gt;% workflowsets::collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard       0.503 Preprocessor1_Model1\n2 rsq     standard       0.999 Preprocessor1_Model1\n\n\n\n\nCode\n# Visualizando as métricas do modelo Elastic Net\nfinalizando_elastic %&gt;% workflowsets::collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard       0.502 Preprocessor1_Model1\n2 rsq     standard       0.999 Preprocessor1_Model1\n\n\nAvaliando o risco preditivo dos modelos, nota-se que o modelo Lasso apresentou um Erro Quadrático Médio (EQM) de \\(0.503\\), enquanto o modelo Elastic Net apresentou um EQM de \\(0.502\\). Além disso, observa-se que ambos os modelos apresentaram um \\(R^{2}\\) de \\(0.999\\). Como o risco preditivo do modelo Elastic Net foi um pouco menor que o do modelo Lasso, então eu escolheria o modelo Elastic Net para fazer as previsões.\n\n\n\nCode\n# Visualizando predições do modelo Lasso\nfinalizando_lasso %&gt;% workflowsets::collect_predictions()\n\n\n# A tibble: 1,000 × 5\n     .pred id                .row       y .config             \n     &lt;dbl&gt; &lt;chr&gt;            &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n 1  16.3   train/test split    14  16.4   Preprocessor1_Model1\n 2  12.8   train/test split    15  12.7   Preprocessor1_Model1\n 3   0.256 train/test split    20   0.182 Preprocessor1_Model1\n 4 -17.4   train/test split    22 -17.9   Preprocessor1_Model1\n 5   9.76  train/test split    23  10.4   Preprocessor1_Model1\n 6  10.6   train/test split    29  10.2   Preprocessor1_Model1\n 7  11.9   train/test split    33  11.3   Preprocessor1_Model1\n 8   4.52  train/test split    36   4.71  Preprocessor1_Model1\n 9  -1.99  train/test split    38  -2.08  Preprocessor1_Model1\n10   6.15  train/test split    44   5.25  Preprocessor1_Model1\n# ℹ 990 more rows\n\n\n\n\nCode\n# Visualizando predições do modelo Elastic Net\nfinalizando_elastic %&gt;% workflowsets::collect_predictions()\n\n\n# A tibble: 1,000 × 5\n     .pred id                .row       y .config             \n     &lt;dbl&gt; &lt;chr&gt;            &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n 1  16.3   train/test split    14  16.4   Preprocessor1_Model1\n 2  12.8   train/test split    15  12.7   Preprocessor1_Model1\n 3   0.261 train/test split    20   0.182 Preprocessor1_Model1\n 4 -17.4   train/test split    22 -17.9   Preprocessor1_Model1\n 5   9.76  train/test split    23  10.4   Preprocessor1_Model1\n 6  10.6   train/test split    29  10.2   Preprocessor1_Model1\n 7  11.9   train/test split    33  11.3   Preprocessor1_Model1\n 8   4.52  train/test split    36   4.71  Preprocessor1_Model1\n 9  -1.99  train/test split    38  -2.08  Preprocessor1_Model1\n10   6.14  train/test split    44   5.25  Preprocessor1_Model1\n# ℹ 990 more rows\n\n\n\n\nCode\n# Extraindo o modelo Lasso\nmodelo_final_lasso &lt;- \n  finalizando_lasso %&gt;% \n  extract_fit_parsnip() \n\n# Extraindo o modelo Elastic Net\nmodelo_final_elastic &lt;- \n  finalizando_elastic %&gt;% \n  extract_fit_parsnip()\n\n\n\n\nCode\n# Visualizando os coeficientes estimados do modelo Lasso\ncoeficientes_lasso &lt;- modelo_final_lasso %&gt;% \n  tidy() %&gt;% \n  filter(term != \"(Intercept)\") %&gt;% print()\n\n\n# A tibble: 20 × 3\n   term  estimate  penalty\n   &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 x1        6.95 1.35e-10\n 2 x2       -4.96 1.35e-10\n 3 x3        1.97 1.35e-10\n 4 x4        3.97 1.35e-10\n 5 x5        8.96 1.35e-10\n 6 x6        0    1.35e-10\n 7 x7        0    1.35e-10\n 8 x8        0    1.35e-10\n 9 x9        0    1.35e-10\n10 x10       0    1.35e-10\n11 x11       0    1.35e-10\n12 x12       0    1.35e-10\n13 x13       0    1.35e-10\n14 x14       0    1.35e-10\n15 x15       0    1.35e-10\n16 x16       0    1.35e-10\n17 x17       0    1.35e-10\n18 x18       0    1.35e-10\n19 x19       0    1.35e-10\n20 x20       0    1.35e-10\n\n\n\n\nCode\n# Visualizando os coeficientes estimados do modelo Elastic Net\ncoeficientes_elastic &lt;- modelo_final_elastic %&gt;% \n  tidy() %&gt;% \n  filter(term != \"(Intercept)\") %&gt;% print()\n\n\n# A tibble: 20 × 3\n   term  estimate       penalty\n   &lt;chr&gt;    &lt;dbl&gt;         &lt;dbl&gt;\n 1 x1        6.95 0.00000000236\n 2 x2       -4.97 0.00000000236\n 3 x3        1.97 0.00000000236\n 4 x4        3.97 0.00000000236\n 5 x5        8.96 0.00000000236\n 6 x6        0    0.00000000236\n 7 x7        0    0.00000000236\n 8 x8        0    0.00000000236\n 9 x9        0    0.00000000236\n10 x10       0    0.00000000236\n11 x11       0    0.00000000236\n12 x12       0    0.00000000236\n13 x13       0    0.00000000236\n14 x14       0    0.00000000236\n15 x15       0    0.00000000236\n16 x16       0    0.00000000236\n17 x17       0    0.00000000236\n18 x18       0    0.00000000236\n19 x19       0    0.00000000236\n20 x20       0    0.00000000236\n\n\n\n\nCode\n# Fazendo previsões \ndados_novos &lt;- dados[sample(1:nrow(dados), 10), -1]\n\n# Fazendo previsões com o modelo Lasso\npredict(finalizando_lasso$.workflow[[1]], \n                           new_data = dados_novos)\n\n\n# A tibble: 10 × 1\n    .pred\n    &lt;dbl&gt;\n 1 -21.5 \n 2   5.58\n 3  16.2 \n 4   1.33\n 5 -18.6 \n 6 -30.6 \n 7   3.25\n 8  17.9 \n 9   9.27\n10  17.4 \n\n\n\n\nCode\n# Fazendo previsões com o modelo Elastic Net\npredict(finalizando_elastic$.workflow[[1]], \n                           new_data = dados_novos)\n\n\n# A tibble: 10 × 1\n    .pred\n    &lt;dbl&gt;\n 1 -21.5 \n 2   5.57\n 3  16.2 \n 4   1.32\n 5 -18.6 \n 6 -30.7 \n 7   3.24\n 8  17.9 \n 9   9.26\n10  17.4 \n\n\n\n\nCode\n# Adicionando as previsões com o modelo Lasso ao conjunto de dados original\naugment(finalizando_lasso$.workflow[[1]], \n                         new_data = dados_novos)\n\n\n# A tibble: 10 × 21\n    .pred     x1     x2     x3     x4     x5    x6    x7    x8    x9   x10   x11\n    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 -21.5  -1.25   0.763 -0.719 -1.25  -0.292     0     0     0     0     0     0\n 2   5.58  1.95   1.29  -1.12   0.403 -0.110     0     0     0     0     0     0\n 3  16.2   1.08  -1.06   0.714  1.70  -0.532     0     0     0     0     0     0\n 4   1.33 -1.02  -1.48  -0.677 -1.24   0.815     0     0     0     0     0     0\n 5 -18.6  -2.03   1.49  -1.40   0.406  0.458     0     0     0     0     0     0\n 6 -30.6  -1.75   1.53  -1.88  -0.506 -0.576     0     0     0     0     0     0\n 7   3.25 -0.988 -0.563 -0.308 -0.195  0.970     0     0     0     0     0     0\n 8  17.9   0.808  0.185  1.36   0.118  1.12      0     0     0     0     0     0\n 9   9.27 -0.148 -0.258  0.806 -1.27   1.39      0     0     0     0     0     0\n10  17.4   0.774  0.509  0.424  0.473  1.32      0     0     0     0     0     0\n# ℹ 9 more variables: x12 &lt;dbl&gt;, x13 &lt;dbl&gt;, x14 &lt;dbl&gt;, x15 &lt;dbl&gt;, x16 &lt;dbl&gt;,\n#   x17 &lt;dbl&gt;, x18 &lt;dbl&gt;, x19 &lt;dbl&gt;, x20 &lt;dbl&gt;\n\n\n\n\nCode\n# Adicionando as previsões com o modelo Elastic Net ao conjunto de dados original\naugment(finalizando_elastic$.workflow[[1]], \n                         new_data = dados_novos)\n\n\n# A tibble: 10 × 21\n    .pred     x1     x2     x3     x4     x5    x6    x7    x8    x9   x10   x11\n    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 -21.5  -1.25   0.763 -0.719 -1.25  -0.292     0     0     0     0     0     0\n 2   5.57  1.95   1.29  -1.12   0.403 -0.110     0     0     0     0     0     0\n 3  16.2   1.08  -1.06   0.714  1.70  -0.532     0     0     0     0     0     0\n 4   1.32 -1.02  -1.48  -0.677 -1.24   0.815     0     0     0     0     0     0\n 5 -18.6  -2.03   1.49  -1.40   0.406  0.458     0     0     0     0     0     0\n 6 -30.7  -1.75   1.53  -1.88  -0.506 -0.576     0     0     0     0     0     0\n 7   3.24 -0.988 -0.563 -0.308 -0.195  0.970     0     0     0     0     0     0\n 8  17.9   0.808  0.185  1.36   0.118  1.12      0     0     0     0     0     0\n 9   9.26 -0.148 -0.258  0.806 -1.27   1.39      0     0     0     0     0     0\n10  17.4   0.774  0.509  0.424  0.473  1.32      0     0     0     0     0     0\n# ℹ 9 more variables: x12 &lt;dbl&gt;, x13 &lt;dbl&gt;, x14 &lt;dbl&gt;, x15 &lt;dbl&gt;, x16 &lt;dbl&gt;,\n#   x17 &lt;dbl&gt;, x18 &lt;dbl&gt;, x19 &lt;dbl&gt;, x20 &lt;dbl&gt;\n\n\n\n\nQuestão 3:\nUtilize o método K - Nearest Neighbors para prever o preço médio ( variável MEDV) de uma casa em diferentes áreas da cidade de Boston com base em várias características socioeconômicas e geográficas. Faça uma descritiva dos dados e realize a fase de preprocessamento dos dados.\n\nVocê deverá:\n\n\nExplorar as variáveis, identificando as variáveis que possuem um comportamento assimétrico;\n\nPré-processar os dados e incluir o preprocessamento no pipeline. No preprocessamento, você deverá:\n\n\n\nRealizar a transformação de Yeo-Johnson nas variáveis que possuem um comportamento assimétrico. No pacote recipes, utilize step_YeoJohnson;\nIncluir no preprocessamento a eliminação de variáveis altamente correlacionadas;\n\nIncluir no preprocessamento a eliminação de covariáveis com zero variância.\n\n\n\nEstimar o risco preditivo do modelo. Houve boas previsões? Explique!\n\nVocê deverá estratificar os dados em \\(80 \\%\\) para treino e \\(20 \\%\\) para teste, com base na variável target.\n\nUtilize na validação cruzada 10-fold cross-validation.\n\n\nAcesse o link para baixar os dados.\n\nResposta:\n\n\nCode\nrm(list = ls())\n\n# Carregando pacotes \nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(tibble)\nlibrary(purrr)\nlibrary(ggplot2)\nlibrary(patchwork)\nlibrary(workflowsets)\nlibrary(yardstick)\nlibrary(glmnet)\nlibrary(kknn)\nlibrary(visdat)\nlibrary(janitor)\nlibrary(parsnip)\nlibrary(skimr)\n\n# Dando preferencias as funcoes do tidymodels \ntidymodels::tidymodels_prefer()\n\n# Setando a semente \nset.seed(0)\n\n# Carregando os dados \ndados &lt;- read.csv(\"~/JOANA/ESTATÍSTICA/2024.1/Aprendizagem de Máquina/AM/Prova2/dados/boston.csv\")\n\n# Limpando os nomes das variáveis \ndados &lt;-\n  dados %&gt;% \n  janitor::clean_names()\n\n\n# Visualizando as primeiras observações dos dados\nhead(dados)\n\n\n     crim zn indus chas   nox    rm  age    dis rad tax ptratio      b lstat\n1 0.00632 18  2.31    0 0.538 6.575 65.2 4.0900   1 296    15.3 396.90  4.98\n2 0.02731  0  7.07    0 0.469 6.421 78.9 4.9671   2 242    17.8 396.90  9.14\n3 0.02729  0  7.07    0 0.469 7.185 61.1 4.9671   2 242    17.8 392.83  4.03\n4 0.03237  0  2.18    0 0.458 6.998 45.8 6.0622   3 222    18.7 394.63  2.94\n5 0.06905  0  2.18    0 0.458 7.147 54.2 6.0622   3 222    18.7 396.90  5.33\n6 0.02985  0  2.18    0 0.458 6.430 58.7 6.0622   3 222    18.7 394.12  5.21\n  medv\n1 24.0\n2 21.6\n3 34.7\n4 33.4\n5 36.2\n6 28.7\n\n\n\n\nCode\n# Visualizando a estrutura dos dados\nglimpse(dados)\n\n\nRows: 506\nColumns: 14\n$ crim    &lt;dbl&gt; 0.00632, 0.02731, 0.02729, 0.03237, 0.06905, 0.02985, 0.08829,…\n$ zn      &lt;dbl&gt; 18.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.5, 12.5, 12.5, 12.5, 12.5, 1…\n$ indus   &lt;dbl&gt; 2.31, 7.07, 7.07, 2.18, 2.18, 2.18, 7.87, 7.87, 7.87, 7.87, 7.…\n$ chas    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ nox     &lt;dbl&gt; 0.538, 0.469, 0.469, 0.458, 0.458, 0.458, 0.524, 0.524, 0.524,…\n$ rm      &lt;dbl&gt; 6.575, 6.421, 7.185, 6.998, 7.147, 6.430, 6.012, 6.172, 5.631,…\n$ age     &lt;dbl&gt; 65.2, 78.9, 61.1, 45.8, 54.2, 58.7, 66.6, 96.1, 100.0, 85.9, 9…\n$ dis     &lt;dbl&gt; 4.0900, 4.9671, 4.9671, 6.0622, 6.0622, 6.0622, 5.5605, 5.9505…\n$ rad     &lt;int&gt; 1, 2, 2, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,…\n$ tax     &lt;dbl&gt; 296, 242, 242, 222, 222, 222, 311, 311, 311, 311, 311, 311, 31…\n$ ptratio &lt;dbl&gt; 15.3, 17.8, 17.8, 18.7, 18.7, 18.7, 15.2, 15.2, 15.2, 15.2, 15…\n$ b       &lt;dbl&gt; 396.90, 396.90, 392.83, 394.63, 396.90, 394.12, 395.60, 396.90…\n$ lstat   &lt;dbl&gt; 4.98, 9.14, 4.03, 2.94, 5.33, 5.21, 12.43, 19.15, 29.93, 17.10…\n$ medv    &lt;dbl&gt; 24.0, 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15…\n\n\n\n\nCode\n# Estatística descritiva dos dados\nskimr::skim(dados)\n\n\n\nData summary\n\n\nName\ndados\n\n\nNumber of rows\n506\n\n\nNumber of columns\n14\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n14\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ncrim\n0\n1\n3.61\n8.60\n0.01\n0.08\n0.26\n3.68\n88.98\n▇▁▁▁▁\n\n\nzn\n0\n1\n11.36\n23.32\n0.00\n0.00\n0.00\n12.50\n100.00\n▇▁▁▁▁\n\n\nindus\n0\n1\n11.14\n6.86\n0.46\n5.19\n9.69\n18.10\n27.74\n▇▆▁▇▁\n\n\nchas\n0\n1\n0.07\n0.25\n0.00\n0.00\n0.00\n0.00\n1.00\n▇▁▁▁▁\n\n\nnox\n0\n1\n0.55\n0.12\n0.38\n0.45\n0.54\n0.62\n0.87\n▇▇▆▅▁\n\n\nrm\n0\n1\n6.28\n0.70\n3.56\n5.89\n6.21\n6.62\n8.78\n▁▂▇▂▁\n\n\nage\n0\n1\n68.57\n28.15\n2.90\n45.02\n77.50\n94.07\n100.00\n▂▂▂▃▇\n\n\ndis\n0\n1\n3.80\n2.11\n1.13\n2.10\n3.21\n5.19\n12.13\n▇▅▂▁▁\n\n\nrad\n0\n1\n9.55\n8.71\n1.00\n4.00\n5.00\n24.00\n24.00\n▇▂▁▁▃\n\n\ntax\n0\n1\n408.24\n168.54\n187.00\n279.00\n330.00\n666.00\n711.00\n▇▇▃▁▇\n\n\nptratio\n0\n1\n18.46\n2.16\n12.60\n17.40\n19.05\n20.20\n22.00\n▁▃▅▅▇\n\n\nb\n0\n1\n356.67\n91.29\n0.32\n375.38\n391.44\n396.22\n396.90\n▁▁▁▁▇\n\n\nlstat\n0\n1\n12.65\n7.14\n1.73\n6.95\n11.36\n16.96\n37.97\n▇▇▅▂▁\n\n\nmedv\n0\n1\n22.53\n9.20\n5.00\n17.02\n21.20\n25.00\n50.00\n▂▇▅▁▁\n\n\n\n\n\nObserva-se que o conjunto de dados contém 506 observações e 14 variáveis. Além disso, observa-se que as variáveis crim, zn, indus, nox, rm, age, dis, tax, ptratio, b, lstat e medv são do tipo numérico, enquanto as variáveis chas e rad são do tipo inteiro categóricas.\n\n\n\nCode\n# Visualizando as variáveis que possuem um comportamento assimétrico\nDescTools::Desc(dados)\n\n\n────────────────────────────────────────────────────────────────────────────── \nDescribe dados (data.frame):\n\ndata frame: 506 obs. of  14 variables\n        506 complete cases (100.0%)\n\n  Nr  Class  ColName  NAs  Levels\n  1   num    crim     .          \n  2   num    zn       .          \n  3   num    indus    .          \n  4   int    chas     .          \n  5   num    nox      .          \n  6   num    rm       .          \n  7   num    age      .          \n  8   num    dis      .          \n  9   int    rad      .          \n  10  num    tax      .          \n  11  num    ptratio  .          \n  12  num    b        .          \n  13  num    lstat    .          \n  14  num    medv     .          \n\n\n────────────────────────────────────────────────────────────────────────────── \n1 - crim (numeric)\n\n     length         n       NAs    unique        0s       mean     meanCI'\n        506       506         0       504         0   3.613524   2.862262\n               100.0%      0.0%                0.0%              4.364786\n                                                                         \n        .05       .10       .25    median       .75        .90        .95\n   0.027910  0.038195  0.082045  0.256510  3.677083  10.753000  15.789150\n                                                                         \n      range        sd     vcoef       mad       IQR       skew       kurt\n  88.969880  8.601545  2.380376  0.328322  3.595038   5.192222  36.595816\n                                                                         \nlowest : 0.00632, 0.00906, 0.01096, 0.01301, 0.01311\nhighest: 45.7461, 51.1358, 67.9208, 73.5341, 88.9762\n\n' 95%-CI (classic)\n\n\n\n\n\n\n\n\n\n────────────────────────────────────────────────────────────────────────────── \n2 - zn (numeric)\n\n  length       n    NAs  unique     0s   mean  meanCI'\n     506     506      0      26    372  11.36    9.33\n          100.0%   0.0%          73.5%          13.40\n                                                     \n     .05     .10    .25  median    .75    .90     .95\n    0.00    0.00   0.00    0.00  12.50  42.50   80.00\n                                                     \n   range      sd  vcoef     mad    IQR   skew    kurt\n  100.00   23.32   2.05    0.00  12.50   2.21    3.95\n                                                     \nlowest : 0.0 (372), 12.5 (10), 17.5, 18.0, 20.0 (21)\nhighest: 82.5 (2), 85.0 (2), 90.0 (5), 95.0 (4), 100.0\n\nheap(?): remarkable frequency (73.5%) for the mode(s) (= 0)\n\n' 95%-CI (classic)\n\n\n\n\n\n\n\n\n\n────────────────────────────────────────────────────────────────────────────── \n3 - indus (numeric)\n\n  length       n    NAs  unique     0s   mean  meanCI'\n     506     506      0      76      0  11.14   10.54\n          100.0%   0.0%           0.0%          11.74\n                                                     \n     .05     .10    .25  median    .75    .90     .95\n    2.18    2.91   5.19    9.69  18.10  19.58   21.89\n                                                     \n   range      sd  vcoef     mad    IQR   skew    kurt\n   27.28    6.86   0.62    9.37  12.91   0.29   -1.24\n                                                     \nlowest : 0.46, 0.74, 1.21, 1.22, 1.25 (2)\nhighest: 18.1 (132), 19.58 (30), 21.89 (15), 25.65 (7), 27.74 (5)\n\nheap(?): remarkable frequency (26.1%) for the mode(s) (= 18.1)\n\n' 95%-CI (classic)\n\n\n\n\n\n\n\n\n\n────────────────────────────────────────────────────────────────────────────── \n4 - chas (integer - dichotomous)\n\n  length      n    NAs unique\n     506    506      0      2\n         100.0%   0.0%       \n\n   freq   perc  lci.95  uci.95'\n0   471  93.1%   90.5%   95.0%\n1    35   6.9%    5.0%    9.5%\n\n' 95%-CI (Wilson)\n\n\n\n\n\n\n\n\n\n────────────────────────────────────────────────────────────────────────────── \n5 - nox (numeric)\n\n   length        n      NAs   unique       0s     mean    meanCI'\n      506      506        0       81        0  0.55470   0.54457\n            100.0%     0.0%              0.0%            0.56482\n                                                                \n      .05      .10      .25   median      .75      .90       .95\n  0.40925  0.42700  0.44900  0.53800  0.62400  0.71300   0.74000\n                                                                \n    range       sd    vcoef      mad      IQR     skew      kurt\n  0.48600  0.11588  0.20890  0.12973  0.17500  0.72499  -0.08741\n                                                                \nlowest : 0.385, 0.389, 0.392 (2), 0.394, 0.398 (2)\nhighest: 0.713 (18), 0.718 (6), 0.74 (13), 0.77 (8), 0.871 (16)\n\n' 95%-CI (classic)\n\n\n\n\n\n\n\n\n\n────────────────────────────────────────────────────────────────────────────── \n6 - rm (numeric)\n\n  length       n     NAs  unique      0s    mean  meanCI'\n     506     506       0     446       0  6.2846  6.2233\n          100.0%    0.0%            0.0%          6.3460\n                                                        \n     .05     .10     .25  median     .75     .90     .95\n  5.3140  5.5935  5.8855  6.2085  6.6235  7.1515  7.5875\n                                                        \n   range      sd   vcoef     mad     IQR    skew    kurt\n  5.2190  0.7026  0.1118  0.5122  0.7380  0.4012  1.8418\n                                                        \nlowest : 3.561, 3.863, 4.138 (2), 4.368, 4.519\nhighest: 8.375, 8.398, 8.704, 8.725, 8.78\n\n' 95%-CI (classic)\n\n\n\n\n\n\n\n\n\n────────────────────────────────────────────────────────────────────────────── \n7 - age (numeric)\n\n  length       n     NAs  unique      0s    mean   meanCI'\n     506     506       0     356       0  68.575   66.116\n          100.0%    0.0%            0.0%           71.033\n                                                         \n     .05     .10     .25  median     .75     .90      .95\n  17.725  26.950  45.025  77.500  94.075  98.800  100.000\n                                                         \n   range      sd   vcoef     mad     IQR    skew     kurt\n  97.100  28.149   0.410  28.985  49.050  -0.595   -0.978\n                                                         \nlowest : 2.9, 6.0, 6.2, 6.5, 6.6 (2)\nhighest: 98.8 (4), 98.9 (3), 99.1, 99.3, 100.0 (43)\n\nheap(?): remarkable frequency (8.5%) for the mode(s) (= 100)\n\n' 95%-CI (classic)\n\n\n\n\n\n\n\n\n\n────────────────────────────────────────────────────────────────────────────── \n8 - dis (numeric)\n\n     length         n       NAs    unique        0s      mean    meanCI'\n        506       506         0       412         0  3.795043  3.611129\n               100.0%      0.0%                0.0%            3.978956\n                                                                       \n        .05       .10       .25    median       .75       .90       .95\n   1.461975  1.628300  2.100175  3.207450  5.188425  6.816600  7.827800\n                                                                       \n      range        sd     vcoef       mad       IQR      skew      kurt\n  10.996900  2.105710  0.554858  1.914259  3.088250  1.005790  0.457592\n                                                                       \nlowest : 1.1296, 1.137, 1.1691, 1.1742, 1.1781\nhighest: 9.2203 (2), 9.2229, 10.5857 (2), 10.7103 (2), 12.1265\n\n' 95%-CI (classic)\n\n\n\n\n\n\n\n\n\n────────────────────────────────────────────────────────────────────────────── \n9 - rad (integer)\n\n  length       n    NAs  unique     0s   mean  meanCI'\n     506     506      0       9      0   9.55    8.79\n          100.0%   0.0%           0.0%          10.31\n                                                     \n     .05     .10    .25  median    .75    .90     .95\n    2.00    3.00   4.00    5.00  24.00  24.00   24.00\n                                                     \n   range      sd  vcoef     mad    IQR   skew    kurt\n   23.00    8.71   0.91    2.97  20.00   1.00   -0.88\n                                                     \n\n   value  freq   perc  cumfreq  cumperc\n1      1    20   4.0%       20     4.0%\n2      2    24   4.7%       44     8.7%\n3      3    38   7.5%       82    16.2%\n4      4   110  21.7%      192    37.9%\n5      5   115  22.7%      307    60.7%\n6      6    26   5.1%      333    65.8%\n7      7    17   3.4%      350    69.2%\n8      8    24   4.7%      374    73.9%\n9     24   132  26.1%      506   100.0%\n\n' 95%-CI (classic)\n\n\n\n\n\n\n\n\n\n────────────────────────────────────────────────────────────────────────────── \n10 - tax (numeric)\n\n  length       n     NAs  unique      0s    mean  meanCI'\n     506     506       0      66       0  408.24  393.52\n          100.0%    0.0%            0.0%          422.96\n                                                        \n     .05     .10     .25  median     .75     .90     .95\n  222.00  233.00  279.00  330.00  666.00  666.00  666.00\n                                                        \n   range      sd   vcoef     mad     IQR    skew    kurt\n  524.00  168.54    0.41  108.23  387.00    0.67   -1.15\n                                                        \nlowest : 187.0, 188.0 (7), 193.0 (8), 198.0, 216.0 (5)\nhighest: 432.0 (9), 437.0 (15), 469.0, 666.0 (132), 711.0 (5)\n\nheap(?): remarkable frequency (26.1%) for the mode(s) (= 666)\n\n' 95%-CI (classic)\n\n\n\n\n\n\n\n\n\n────────────────────────────────────────────────────────────────────────────── \n11 - ptratio (numeric)\n\n  length       n    NAs  unique     0s   mean  meanCI'\n     506     506      0      46      0  18.46   18.27\n          100.0%   0.0%           0.0%          18.64\n                                                     \n     .05     .10    .25  median    .75    .90     .95\n   14.70   14.75  17.40   19.05  20.20  20.90   21.00\n                                                     \n   range      sd  vcoef     mad    IQR   skew    kurt\n    9.40    2.16   0.12    1.70   2.80  -0.80   -0.30\n                                                     \nlowest : 12.6 (3), 13.0 (12), 13.6, 14.4, 14.7 (34)\nhighest: 20.9 (11), 21.0 (27), 21.1, 21.2 (15), 22.0 (2)\n\nheap(?): remarkable frequency (27.7%) for the mode(s) (= 20.2)\n\n' 95%-CI (classic)\n\n\n\n\n\n\n\n\n\n────────────────────────────────────────────────────────────────────────────── \n12 - b (numeric)\n\n    length         n       NAs    unique        0s      mean    meanCI'\n       506       506         0       357         0  356.6740  348.7003\n              100.0%      0.0%                0.0%            364.6478\n                                                                      \n       .05       .10       .25    median       .75       .90       .95\n   84.5900  290.2700  375.3775  391.4400  396.2250  396.9000  396.9000\n                                                                      \n     range        sd     vcoef       mad       IQR      skew      kurt\n  396.5800   91.2949    0.2560    8.0950   20.8475   -2.8733    7.1037\n                                                                      \nlowest : 0.32, 2.52, 2.6, 3.5, 3.65\nhighest: 396.28, 396.3, 396.33, 396.42, 396.9 (121)\n\nheap(?): remarkable frequency (23.9%) for the mode(s) (= 396.9)\n\n' 95%-CI (classic)\n\n\n\n\n\n\n\n\n\n────────────────────────────────────────────────────────────────────────────── \n13 - lstat (numeric)\n\n   length       n     NAs   unique       0s     mean   meanCI'\n      506     506       0      455        0  12.6531  12.0294\n           100.0%    0.0%              0.0%           13.2768\n                                                             \n      .05     .10     .25   median      .75      .90      .95\n   3.7075  4.6800  6.9500  11.3600  16.9550  23.0350  26.8075\n                                                             \n    range      sd   vcoef      mad      IQR     skew     kurt\n  36.2400  7.1411  0.5644   7.1091  10.0050   0.9011   0.4628\n                                                             \nlowest : 1.73, 1.92, 1.98, 2.47, 2.87\nhighest: 34.37, 34.41, 34.77, 36.98, 37.97\n\n' 95%-CI (classic)\n\n\n\n\n\n\n\n\n\n────────────────────────────────────────────────────────────────────────────── \n14 - medv (numeric)\n\n  length       n     NAs  unique      0s    mean  meanCI'\n     506     506       0     229       0  22.533  21.730\n          100.0%    0.0%            0.0%          23.336\n                                                        \n     .05     .10     .25  median     .75     .90     .95\n  10.200  12.750  17.025  21.200  25.000  34.800  43.400\n                                                        \n   range      sd   vcoef     mad     IQR    skew    kurt\n  45.000   9.197   0.408   5.930   7.975   1.102   1.451\n                                                        \nlowest : 5.0 (2), 5.6, 6.3, 7.0 (2), 7.2 (3)\nhighest: 46.7, 48.3, 48.5, 48.8, 50.0 (16)\n\n' 95%-CI (classic)\n\n\n\n\n\n\n\n\n\nUtilizando a função Desc() da library DescTools para analisar visualmente as variáveis que possuem um comportamento assimétrico, e avaliando a assimetria das variáveis com base do valor do argumento skew de cada variável, nota-se que as variáveis indus e rm possuem um comportamento simétrico, pois o valor do skewdestas variáveis estão próximos de zero, enquanto as variáveis crim, zn, nox, age, dis, tax, ptratio, b, lstat e medv possuem um comportamento assimétrico.\n\n\n\nCode\n# Olhando rapidamento os dados\nvisdat::vis_dat(dados)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Visualizando a correlação entre as variáveis \nvisdat::vis_cor(dados)\n\n\n\n\n\n\n\n\n\n\n\nCode\nset.seed(0)\n\n# Data Splitting\ndados_split &lt;- rsample::initial_split(dados, prop = 0.8, strata = \"medv\")\ntreino &lt;- rsample::training(dados_split)\nteste &lt;- rsample::testing(dados_split)\n\n# Criando o conjunto de validação\ncv &lt;- rsample::vfold_cv(treino, v = 10L)\n\n# Pré-processamento dos dados \nreceita &lt;- \n  recipes::recipe(medv ~ ., data = treino) %&gt;%\n  # Eliminando as variáveis constantes (com zero variância)\n  recipes::step_zv(all_predictors()) %&gt;%\n  # Transformando as variáveis assimétricas\n  recipes::step_YeoJohnson(all_numeric_predictors()) %&gt;%\n  # Transformando as variáveis categóricas em dicotômicas (0 e 1) \n  recipes::step_dummy(all_nominal_predictors()) %&gt;%\n  # Eliminando as variáveis altamente correlacionadas\n  recipes::step_corr(all_numeric_predictors()) \n\n\n\n\nCode\n# Ajustando o modelo KNN \nmodelo_knn &lt;- \n  parsnip::nearest_neighbor(neighbors = tune(\"k\")) %&gt;% \n  parsnip::set_mode(\"regression\") %&gt;% \n  parsnip::set_engine(\"kknn\")\n\n\n\n\nCode\n# Criando o Workflow \nwf &lt;- \n  workflowsets::workflow_set(\n    preproc = list(formula = receita),\n    models = list(knn = modelo_knn), \n    cross = TRUE\n  )\n\n\n\n\nCode\n# Setando a métrica\nmetrica &lt;- yardstick::metric_set(rmse)\n\n# Tunagem dos hiperparâmetros\ntunagem &lt;- \n  wf %&gt;% \n  workflowsets::workflow_map(\n    seed = 0, \n    verbose = TRUE,\n    resamples = cv,\n    grid = 50,\n    metrics = metrica\n  )\n\n\ni 1 of 1 tuning:     formula_knn\n\n\n✔ 1 of 1 tuning:     formula_knn (5.1s)\n\n\n\n\nCode\n# Selecionando o melhor modelo\nmelhor_knn &lt;- \n  tunagem %&gt;% \n  workflowsets::extract_workflow_set_result(\"formula_knn\") %&gt;% \n  tune::select_best(metric = \"rmse\")\n\n# Finalizando o modelo\nfinalizando_knn &lt;-\n  tunagem %&gt;% \n  workflowsets::extract_workflow(\"formula_knn\") %&gt;% \n  tune::finalize_workflow(melhor_knn) %&gt;% \n  tune::last_fit(split = dados_split)\n\n\n\n\nCode\n# Visualizando as métricas do modelo KNN\nfinalizando_knn %&gt;% workflowsets::collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard       4.74  Preprocessor1_Model1\n2 rsq     standard       0.730 Preprocessor1_Model1\n\n\nEm relação ao risco preditivo do modelo KNN, observa-se que o Erro Quadrático Médio (EQM) foi de \\(4.74\\) e o \\(R^{2}\\) de \\(0.730\\), o EQM foi relativamente bom, mas como o \\(R^{2}\\) não é muito alto, é provável que o modelo não faça boas previsões para alguns preços médios das casas de diferentes áreas da cidade de Boston.\n\n\n\nCode\n# Visualizando predições do modelo KNN\nfinalizando_knn %&gt;% workflowsets::collect_predictions()\n\n\n# A tibble: 103 × 5\n   .pred id                .row  medv .config             \n   &lt;dbl&gt; &lt;chr&gt;            &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;               \n 1  18.1 train/test split    18  17.5 Preprocessor1_Model1\n 2  14.1 train/test split    21  13.6 Preprocessor1_Model1\n 3  16.7 train/test split    23  15.2 Preprocessor1_Model1\n 4  16.1 train/test split    24  14.5 Preprocessor1_Model1\n 5  16.6 train/test split    27  16.6 Preprocessor1_Model1\n 6  18.4 train/test split    30  21   Preprocessor1_Model1\n 7  18.1 train/test split    32  14.5 Preprocessor1_Model1\n 8  20.3 train/test split    37  20   Preprocessor1_Model1\n 9  31.0 train/test split    41  34.9 Preprocessor1_Model1\n10  23.6 train/test split    43  25.3 Preprocessor1_Model1\n# ℹ 93 more rows\n\n\nAnalisando algumas predições acima do modelo KNN, observa-se que o modelo fez boas previsões para os preços médios (medv) em sua grande parte, porém para alguns preços médios o modelo não fez boas previsões.\n\n\n\nCode\n# Extraindo o modelo KNN\nmodelo_final_knn &lt;- \n  finalizando_knn %&gt;% \n  extract_fit_parsnip()\n\n\n\n\nCode\n# Fazendo previsões \ndados_novos &lt;- dados[sample(1:nrow(dados), 10), ]\n\n# Fazendo previsões com o modelo KNN\npredict(finalizando_knn$.workflow[[1]], \n                           new_data = dados_novos) \n\n\n# A tibble: 10 × 1\n   .pred\n   &lt;dbl&gt;\n 1  16.1\n 2  23.0\n 3  12.8\n 4  28.0\n 5  19.4\n 6  13.4\n 7  24.7\n 8  34.1\n 9  19.1\n10  24.5\n\n\n\n\nCode\n# Adicionando as previsões com o modelo KNN ao conjunto de dados original\nprevisoes_knn &lt;- augment(finalizando_knn$.workflow[[1]], \n                         new_data = dados_novos) %&gt;% print()\n\n\n# A tibble: 10 × 16\n   .pred .resid    crim    zn indus  chas   nox    rm   age   dis   rad   tax\n   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;\n 1  16.1 -0.475  4.10       0 19.6      0 0.871  5.47 100    1.41     5   403\n 2  23.0  1.13   0.0790     0 12.8      0 0.437  6.27   6    4.25     5   398\n 3  12.8 -1.07  13.9        0 18.1      0 0.713  6.21  95    2.22    24   666\n 4  28.0 -4.05   0.0254    55  3.78     0 0.484  6.70  56.4  5.73     5   370\n 5  19.4 -0.199  0.340      0 21.9      0 0.624  6.46  98.9  2.12     4   437\n 6  13.4  1.47   9.51       0 18.1      0 0.713  6.73  94.1  2.50    24   666\n 7  24.7  0.293  0.0288    28 15.0      0 0.464  6.21  28.9  3.67     4   270\n 8  34.1 -0.957  0.0613    40  6.41     1 0.447  6.83  27.6  4.86     4   254\n 9  19.1  0.742  0.245      0  9.9      0 0.544  5.78  71.7  4.03     4   304\n10  24.5 -1.25   1.43       0 19.6      0 0.871  6.51 100    1.77     5   403\n# ℹ 4 more variables: ptratio &lt;dbl&gt;, b &lt;dbl&gt;, lstat &lt;dbl&gt;, medv &lt;dbl&gt;\n\n\n\n\nCode\n# Adicionando as previsões com o modelo KNN ao conjunto de dados original\nprevisoes_knn[, c(\"medv\", \".pred\")] %&gt;% print()\n\n\n# A tibble: 10 × 2\n    medv .pred\n   &lt;dbl&gt; &lt;dbl&gt;\n 1  15.6  16.1\n 2  24.1  23.0\n 3  11.7  12.8\n 4  23.9  28.0\n 5  19.2  19.4\n 6  14.9  13.4\n 7  25    24.7\n 8  33.1  34.1\n 9  19.8  19.1\n10  23.3  24.5\n\n\nObserva-se que o modelo fez boas previsões para os preços médios (medv) em sua grande parte, porém para alguns preços médios o modelo não fez boas previsões.\n\n\n\nQuestão 4:\nCom base na questão 1, escolha entre as 5 features preditoras que foram úteis para gerar \\(y\\), duas para introduzir \\(10 \\%\\) de missing values em cada uma dessas duas variáveis. A introdução das observações faltantes deverá ser aleatória. Após, isso, realize a comparação do método Elastic-Net com o método K - Nearest Neighbors - KNN. Compare o risco preditivo de cada um do modelos. Na fase de pré-processamento, você deverá utilizar também o método KNN, considerando \\(k =5\\) dados faltantes. Qual o modelo que forneceu um melhor risco preditivo? Explique!\n\nResposta:\n\n\nCode\nrm(list = ls())\n\n# Carregando pacotes \nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(tibble)\nlibrary(purrr)\nlibrary(ggplot2)\nlibrary(patchwork)\nlibrary(workflowsets)\nlibrary(yardstick)\nlibrary(glmnet)\nlibrary(kknn)\nlibrary(visdat)\n\n# Dando preferencias as funcoes do tidymodels \ntidymodels::tidymodels_prefer()\n\n# Setando a semente \nset.seed(0)\n\n# Função para gerar os dados \ngerando_dados &lt;- function(n = 5000L){\n  regressao &lt;- function(i){\n    x &lt;- rnorm(n = 5000L, 0, 1)\n    target &lt;- 7*x[1L] - 5*x[2L] + 2*x[3L] + 4*x[4L] + 9*x[5L] + rnorm(1L, 0, 0.5)\n    tibble(\n      y = target,\n      x1 = x[1L],\n      x2 = x[2L],\n      x3 = x[3L],\n      x4 = x[4L],\n      x5 = x[5L]\n    )\n  }\n  dados &lt;- purrr::map(.x = 1L:n, .f = regressao) %&gt;% \n    purrr::list_rbind()\n  \n  parte_esparsa &lt;- matrix(0, n, 15)\n  \n  dados &lt;- cbind(dados, parte_esparsa)\n  colnames(dados) &lt;- c(\"y\", paste0(\"x\", 1L:20L))\n  tibble::as_tibble(dados)\n}\n\ndados &lt;- gerando_dados()\n\n\n\n\nCode\nset.seed(0) \n\n# Introduzindo 10% missing values nas variáveis x3 e x5 de forma aleatória\nid_na &lt;- sample(1:nrow(dados), 0.1*nrow(dados))\ndados[id_na, \"x3\"] &lt;- NA\ndados[id_na, \"x5\"] &lt;- NA\n\n\n\n\nCode\n# Olhando rapidamento os dados \nvisdat::vis_dat(dados)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Visualizando a correlação entre as variáveis\nvisdat::vis_cor(dados[-c(7:21)])\n\n\n\n\n\n\n\n\n\n\n\nCode\nset.seed(0)\n\n# Data Splitting\ndados_split &lt;- rsample::initial_split(dados, prop = 0.8, strata = \"y\")\ntreino &lt;- rsample::training(dados_split)\nteste &lt;- rsample::testing(dados_split)\n\n# Criando o conjunto de validação\ncv &lt;- rsample::vfold_cv(treino, v = 10L)\n\n# Pré-processamento dos dados \nreceita &lt;- \n  recipe(y ~ ., data = treino) %&gt;%\n  # Eliminando as variáveis constantes (com zero variância)\n  recipes::step_zv(all_predictors()) %&gt;%\n  # Normalizando as variáveis numéricas\n  recipes::step_normalize(all_numeric_predictors()) %&gt;%\n  #considerando k = 5 para inputar os dados faltantes\n  recipes::step_impute_knn(all_predictors(), neighbors = 5)  \n\n\n\n\nCode\n# Setando o modelo (set engine) \nmodelo_elastic &lt;- \n  parsnip::linear_reg(penalty = tune::tune(), mixture = tune::tune()) %&gt;% \n  parsnip::set_mode(\"regression\") %&gt;% \n  parsnip::set_engine(\"glmnet\")\n\nmodelo_knn &lt;- \n  parsnip::nearest_neighbor(neighbors = tune(\"k\")) %&gt;% \n  parsnip::set_mode(\"regression\") %&gt;% \n  parsnip::set_engine(\"kknn\")\n\n\n\n\nCode\n# Criando workflows \nall_wf &lt;- \n  workflowsets::workflow_set(\n    preproc = list(formula = receita),\n    models = list(elastic = modelo_elastic, knn = modelo_knn), \n    cross = TRUE\n  )\n\n\n\n\nCode\n# Setando a métrica \nmetrica &lt;- yardstick::metric_set(rmse)\n\n# Tunagem dos hiperparâmetros \ntunagem &lt;- \n  all_wf %&gt;% \n  workflowsets::workflow_map(\n    seed = 0, \n    verbose = TRUE,\n    resamples = cv,\n    grid = 50,\n    metrics = metrica\n  )\n\n\ni 1 of 2 tuning:     formula_elastic\n\n\n✔ 1 of 2 tuning:     formula_elastic (1m 17.7s)\n\n\ni 2 of 2 tuning:     formula_knn\n\n\n✔ 2 of 2 tuning:     formula_knn (27.3s)\n\n\n\n\nCode\n# Rank dos melhores modelos \nmodelos_rank &lt;- tunagem %&gt;% workflowsets::rank_results() %&gt;% print()\n\n\n# A tibble: 65 × 9\n   wflow_id        .config  .metric  mean std_err     n preprocessor model  rank\n   &lt;chr&gt;           &lt;chr&gt;    &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n 1 formula_elastic Preproc… rmse     3.29   0.162    10 recipe       line…     1\n 2 formula_elastic Preproc… rmse     3.29   0.162    10 recipe       line…     2\n 3 formula_elastic Preproc… rmse     3.29   0.162    10 recipe       line…     3\n 4 formula_elastic Preproc… rmse     3.29   0.162    10 recipe       line…     4\n 5 formula_elastic Preproc… rmse     3.29   0.162    10 recipe       line…     5\n 6 formula_elastic Preproc… rmse     3.29   0.162    10 recipe       line…     6\n 7 formula_elastic Preproc… rmse     3.29   0.162    10 recipe       line…     7\n 8 formula_elastic Preproc… rmse     3.29   0.162    10 recipe       line…     8\n 9 formula_elastic Preproc… rmse     3.29   0.162    10 recipe       line…     9\n10 formula_elastic Preproc… rmse     3.29   0.162    10 recipe       line…    10\n# ℹ 55 more rows\n\n\n\n\nCode\n# Selecionando os melhores modelos \nmelhor_elastic &lt;- \n  tunagem %&gt;% \n  workflowsets::extract_workflow_set_result(\"formula_elastic\") %&gt;% \n  tune::select_best(metric = \"rmse\")\n\nmelhor_knn &lt;- \n  tunagem %&gt;% \n  workflowsets::extract_workflow_set_result(\"formula_knn\") %&gt;% \n  tune::select_best(metric = \"rmse\")\n\n# Finalizando os modelos \nfinalizando_elastic &lt;- \n  tunagem %&gt;% \n  workflowsets::extract_workflow(\"formula_elastic\") %&gt;% \n  tune::finalize_workflow(melhor_elastic) %&gt;% \n  tune::last_fit(split = dados_split)\n\nfinalizando_knn &lt;-\n  tunagem %&gt;% \n  workflowsets::extract_workflow(\"formula_knn\") %&gt;% \n  tune::finalize_workflow(melhor_knn) %&gt;% \n  tune::last_fit(split = dados_split)\n\n\n\n\nCode\n# Visualizando as métricas do modelo Elastic Net\nfinalizando_elastic %&gt;% workflowsets::collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard       3.41  Preprocessor1_Model1\n2 rsq     standard       0.930 Preprocessor1_Model1\n\n\n\n\nCode\n# Visualizando as métricas do modelo KNN\nfinalizando_knn %&gt;% workflowsets::collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard       4.15  Preprocessor1_Model1\n2 rsq     standard       0.906 Preprocessor1_Model1\n\n\nAvaliando o risco preditivo dos modelos, nota-se que o modelo Elastic Net apresentou um Erro Quadrático Médio (EQM) de \\(3.41\\), enquanto o modelo KNN apresentou um EQM de \\(4.15\\). Além disso, observa-se que o modelo Elastic Net apresentou um \\(R^{2}\\) de \\(0.930\\), enquanto para o modelo KNN o \\(R^{2}\\) foi de \\(0.906\\). Como o EQM do modelo Elastic Net foi menor que o do modelo KNN, além do \\(R^{2}\\) do modelo Elastic Net ter sido maior que o do KNN, logo o modelo Elastic Net nos forneceu um melhor risco preditivo que o KNN.\n\n\n\nCode\n# Visualizando predições do modelo Elastic Net\nfinalizando_elastic %&gt;% workflowsets::collect_predictions()\n\n\n# A tibble: 1,000 × 5\n    .pred id                .row      y .config             \n    &lt;dbl&gt; &lt;chr&gt;            &lt;int&gt;  &lt;dbl&gt; &lt;chr&gt;               \n 1   7.87 train/test split     5   7.74 Preprocessor1_Model1\n 2 -23.2  train/test split     7 -23.7  Preprocessor1_Model1\n 3  -8.77 train/test split     9  -8.79 Preprocessor1_Model1\n 4  -3.62 train/test split    19  -3.46 Preprocessor1_Model1\n 5  -6.38 train/test split    22 -17.9  Preprocessor1_Model1\n 6  -5.22 train/test split    24  -5.46 Preprocessor1_Model1\n 7  10.8  train/test split    31  11.5  Preprocessor1_Model1\n 8   4.62 train/test split    36   4.71 Preprocessor1_Model1\n 9  -9.53 train/test split    37   3.42 Preprocessor1_Model1\n10  19.4  train/test split    43  19.2  Preprocessor1_Model1\n# ℹ 990 more rows\n\n\n\n\nCode\n# Visualizando predições do modelo KNN\nfinalizando_knn %&gt;% workflowsets::collect_predictions()\n\n\n# A tibble: 1,000 × 5\n    .pred id                .row      y .config             \n    &lt;dbl&gt; &lt;chr&gt;            &lt;int&gt;  &lt;dbl&gt; &lt;chr&gt;               \n 1   5.18 train/test split     5   7.74 Preprocessor1_Model1\n 2 -17.5  train/test split     7 -23.7  Preprocessor1_Model1\n 3 -10.2  train/test split     9  -8.79 Preprocessor1_Model1\n 4  -2.10 train/test split    19  -3.46 Preprocessor1_Model1\n 5  -4.44 train/test split    22 -17.9  Preprocessor1_Model1\n 6  -4.17 train/test split    24  -5.46 Preprocessor1_Model1\n 7  12.3  train/test split    31  11.5  Preprocessor1_Model1\n 8   4.74 train/test split    36   4.71 Preprocessor1_Model1\n 9  -5.85 train/test split    37   3.42 Preprocessor1_Model1\n10  18.5  train/test split    43  19.2  Preprocessor1_Model1\n# ℹ 990 more rows\n\n\n\n\nCode\n# Extraindo o modelo Elastic Net\nmodelo_final_elastic &lt;- \n  finalizando_elastic %&gt;% \n  extract_fit_parsnip()\n\n# Extraindo o modelo KNN\nmodelo_final_knn &lt;- \n  finalizando_knn %&gt;% \n  extract_fit_parsnip()\n\n\n\n\nQuestão 5:\nConsidere a base de dados referente à despesas médicas, cujo o objetivo é predizer a variável charges. Clique aqui para efetuar o download dos dados. Considere os algoritmos, lasso, ridge, elastic net e KNN e compare o risco preditivo de cada um dos modelos.\n\nVocê deverá utilizar boas práticas na comparação, explorar os dados e avaliar de forma adequada o risco preditivo de cada um dos modelos considerados. Perceba que existem variáveis categóricas na base de dados. Dessa forma, você deverá introduzir no pipeline o pré-processamento. Discuta o resultado.\n\nResposta:\n\n\nCode\nrm(list = ls())\n\n# Carregando pacotes \nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(tibble)\nlibrary(purrr)\nlibrary(ggplot2)\nlibrary(patchwork)\nlibrary(workflowsets)\nlibrary(yardstick)\nlibrary(glmnet)\nlibrary(kknn)\nlibrary(visdat)\n\n# Dando preferencias as funcoes do tidymodels \ntidymodels::tidymodels_prefer()\n\n# Setando a semente \nset.seed(0)\n\n# Carregando os dados \ndados &lt;- read.csv(\"~/JOANA/ESTATÍSTICA/2024.1/Aprendizagem de Máquina/AM/Prova2/dados/insurance.csv\")\n\n# Visualizando as primeiras observações dos dados\nhead(dados)\n\n\n  age    sex    bmi children smoker    region   charges\n1  19 female 27.900        0    yes southwest 16884.924\n2  18   male 33.770        1     no southeast  1725.552\n3  28   male 33.000        3     no southeast  4449.462\n4  33   male 22.705        0     no northwest 21984.471\n5  32   male 28.880        0     no northwest  3866.855\n6  31 female 25.740        0     no southeast  3756.622\n\n\n\n\nCode\n# Visualizando a estrutura dos dados\nglimpse(dados)\n\n\nRows: 1,338\nColumns: 7\n$ age      &lt;int&gt; 19, 18, 28, 33, 32, 31, 46, 37, 37, 60, 25, 62, 23, 56, 27, 1…\n$ sex      &lt;chr&gt; \"female\", \"male\", \"male\", \"male\", \"male\", \"female\", \"female\",…\n$ bmi      &lt;dbl&gt; 27.900, 33.770, 33.000, 22.705, 28.880, 25.740, 33.440, 27.74…\n$ children &lt;int&gt; 0, 1, 3, 0, 0, 0, 1, 3, 2, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0…\n$ smoker   &lt;chr&gt; \"yes\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", …\n$ region   &lt;chr&gt; \"southwest\", \"southeast\", \"southeast\", \"northwest\", \"northwes…\n$ charges  &lt;dbl&gt; 16884.924, 1725.552, 4449.462, 21984.471, 3866.855, 3756.622,…\n\n\n\n\nCode\n# Olhando rapidamento os dados \nvisdat::vis_dat(dados)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Visualizando a correlação entre as variáveis \nvisdat::vis_cor(dados[-c(2,5,6)])\n\n\n\n\n\n\n\n\n\n\n\nCode\nset.seed(0)\n\n# Data Splitting\ndados_split &lt;- rsample::initial_split(dados, prop = 0.8, strata = \"charges\")\ntreino &lt;- rsample::training(dados_split)\nteste &lt;- rsample::testing(dados_split)\n\n# Criando o conjunto de validação\ncv &lt;- rsample::vfold_cv(treino, v = 5L)\n\n# Pré-processamento dos dados \nreceita &lt;- \n  recipe(charges ~ ., data = treino) %&gt;%\n  # Eliminando as variáveis constantes (com zero variância)\n  recipes::step_zv(all_predictors()) %&gt;%\n  # Normalizando as variáveis numéricas\n  recipes::step_normalize(all_numeric_predictors()) %&gt;%\n  # Transformando as variáveis categóricas em dicotômicas (0 e 1) \n  step_dummy(all_nominal_predictors()) %&gt;%\n  # Eliminando as variáveis correlacionadas\n  recipes::step_corr(all_numeric_predictors()) \n\n\n\n\nCode\n# Setando o modelo (set engine) \nmodelo_ridge &lt;- \n  parsnip::linear_reg(penalty = tune::tune(), mixture = 0) %&gt;% \n  parsnip::set_mode(\"regression\") %&gt;% \n  parsnip::set_engine(\"glmnet\")\n\nmodelo_lasso &lt;- \n  parsnip::linear_reg(penalty = tune::tune(), mixture = 1) %&gt;% \n  parsnip::set_mode(\"regression\") %&gt;% \n  parsnip::set_engine(\"glmnet\")\n\nmodelo_elastic &lt;- \n  parsnip::linear_reg(penalty = tune::tune(), mixture = tune::tune()) %&gt;% \n  parsnip::set_mode(\"regression\") %&gt;% \n  parsnip::set_engine(\"glmnet\")\n\nmodelo_knn &lt;- \n  parsnip::nearest_neighbor(neighbors = tune(\"k\")) %&gt;% \n  parsnip::set_mode(\"regression\") %&gt;% \n  parsnip::set_engine(\"kknn\")\n\n\n\n\nCode\n# Criando workflows \nall_wf &lt;- \n  workflowsets::workflow_set(\n    preproc = list(formula = receita),\n    models = list(ridge = modelo_ridge, lasso = modelo_lasso, \n                  elastic = modelo_elastic, knn = modelo_knn), \n    cross = TRUE\n  )\n\n\n\n\nCode\n# Setando a métrica \nmetrica &lt;- yardstick::metric_set(rmse)\n\n# Tunagem dos hiperparâmetros \ntunagem &lt;- \n  all_wf %&gt;% \n  workflowsets::workflow_map(\n    seed = 0, \n    verbose = TRUE,\n    resamples = cv,\n    grid = 50,\n    metrics = metrica\n  )\n\n\ni 1 of 4 tuning:     formula_ridge\n\n\n✔ 1 of 4 tuning:     formula_ridge (1.8s)\n\n\ni 2 of 4 tuning:     formula_lasso\n\n\n✔ 2 of 4 tuning:     formula_lasso (1.8s)\n\n\ni 3 of 4 tuning:     formula_elastic\n\n\n✔ 3 of 4 tuning:     formula_elastic (25s)\n\n\ni 4 of 4 tuning:     formula_knn\n\n\n✔ 4 of 4 tuning:     formula_knn (4.7s)\n\n\n\n\nCode\n# Rank dos melhores modelos \nmodelos_rank &lt;- tunagem %&gt;% workflowsets::rank_results() %&gt;% print()\n\n\n# A tibble: 165 × 9\n   wflow_id    .config      .metric  mean std_err     n preprocessor model  rank\n   &lt;chr&gt;       &lt;chr&gt;        &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n 1 formula_knn Preprocesso… rmse    5363.    186.     5 recipe       near…     1\n 2 formula_knn Preprocesso… rmse    5365.    190.     5 recipe       near…     2\n 3 formula_knn Preprocesso… rmse    5366.    182.     5 recipe       near…     3\n 4 formula_knn Preprocesso… rmse    5367.    194.     5 recipe       near…     4\n 5 formula_knn Preprocesso… rmse    5370.    197.     5 recipe       near…     5\n 6 formula_knn Preprocesso… rmse    5374.    176.     5 recipe       near…     6\n 7 formula_knn Preprocesso… rmse    5388.    171.     5 recipe       near…     7\n 8 formula_knn Preprocesso… rmse    5409.    166.     5 recipe       near…     8\n 9 formula_knn Preprocesso… rmse    5437.    159.     5 recipe       near…     9\n10 formula_knn Preprocesso… rmse    5471.    153.     5 recipe       near…    10\n# ℹ 155 more rows\n\n\n\n\nCode\n# Selecionando os melhores modelos \nmelhor_ridge &lt;- \n  tunagem %&gt;% \n  workflowsets::extract_workflow_set_result(\"formula_ridge\") %&gt;% \n  tune::select_best(metric = \"rmse\")\n\nmelhor_lasso &lt;- \n  tunagem %&gt;% \n  workflowsets::extract_workflow_set_result(\"formula_lasso\") %&gt;% \n  tune::select_best(metric =\"rmse\")\n\nmelhor_elastic &lt;- \n  tunagem %&gt;% \n  workflowsets::extract_workflow_set_result(\"formula_elastic\") %&gt;% \n  tune::select_best(metric = \"rmse\")\n\nmelhor_knn &lt;- \n  tunagem %&gt;% \n  workflowsets::extract_workflow_set_result(\"formula_knn\") %&gt;% \n  tune::select_best(metric = \"rmse\")\n\n# Finalizando os modelos \nfinalizando_ridge &lt;- \n  tunagem %&gt;% \n  workflowsets::extract_workflow(\"formula_ridge\") %&gt;% \n  tune::finalize_workflow(melhor_ridge) %&gt;% \n  tune::last_fit(split = dados_split)\n\nfinalizando_lasso &lt;- \n  tunagem %&gt;% \n  workflowsets::extract_workflow(\"formula_lasso\") %&gt;% \n  tune::finalize_workflow(melhor_lasso) %&gt;% \n  tune::last_fit(split = dados_split)\n\nfinalizando_elastic &lt;- \n  tunagem %&gt;% \n  workflowsets::extract_workflow(\"formula_elastic\") %&gt;% \n  tune::finalize_workflow(melhor_elastic) %&gt;% \n  tune::last_fit(split = dados_split)\n\nfinalizando_knn &lt;-\n  tunagem %&gt;% \n  workflowsets::extract_workflow(\"formula_knn\") %&gt;% \n  tune::finalize_workflow(melhor_knn) %&gt;% \n  tune::last_fit(split = dados_split)\n\n\n\n\nCode\n# Visualizando as métricas do modelo Ridge\nfinalizando_ridge %&gt;% workflowsets::collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard    6530.    Preprocessor1_Model1\n2 rsq     standard       0.744 Preprocessor1_Model1\n\n\n\n\nCode\n# Visualizando as métricas do modelo Lasso\nfinalizando_lasso %&gt;% workflowsets::collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard    6442.    Preprocessor1_Model1\n2 rsq     standard       0.743 Preprocessor1_Model1\n\n\n\n\nCode\n# Visualizando as métricas do modelo Elastic Net\nfinalizando_elastic %&gt;% workflowsets::collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard    6446.    Preprocessor1_Model1\n2 rsq     standard       0.743 Preprocessor1_Model1\n\n\n\n\nCode\n# Visualizando as métricas do modelo KNN\nfinalizando_knn %&gt;% workflowsets::collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard    5550.    Preprocessor1_Model1\n2 rsq     standard       0.811 Preprocessor1_Model1\n\n\nComparando o risco preditivo dos modelos, observa-se que o modelo KNN foi o que apresentou o melhor risco preditivo com um menor Erro Quadrático Médio (EQM) de \\(5550\\) e um maior \\(R^{2}\\) de \\(0.811\\). O modelo Lasso obteve um EQM de \\(6442\\), enquanto o modelo Elastic Net apresentou um EQM de \\(6446\\), em que ambos tiveram um \\(R^{2}\\) de \\(0.743\\). Por fim, o modelo que mostrou um pior desempenho foi o Ridge, com um maior EQM de \\(6530\\) e \\(R^{2}\\) de \\(0.744\\).\n\n\n\nCode\n# Visualizando predições do modelo Ridge\nfinalizando_ridge %&gt;% workflowsets::collect_predictions()\n\n\n# A tibble: 268 × 5\n    .pred id                .row charges .config             \n    &lt;dbl&gt; &lt;chr&gt;            &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n 1  4479. train/test split     4  21984. Preprocessor1_Model1\n 2  3903. train/test split    11   2721. Preprocessor1_Model1\n 3 33465. train/test split    12  27809. Preprocessor1_Model1\n 4  5090. train/test split    13   1827. Preprocessor1_Model1\n 5  1604. train/test split    16   1837. Preprocessor1_Model1\n 6  2688. train/test split    18   2395. Preprocessor1_Model1\n 7  3690. train/test split    23   1137. Preprocessor1_Model1\n 8  1027. train/test split    29   2775. Preprocessor1_Model1\n 9 37300. train/test split    40  48173. Preprocessor1_Model1\n10  7315. train/test split    48   3557. Preprocessor1_Model1\n# ℹ 258 more rows\n\n\n\n\nCode\n# Visualizando predições do modelo Lasso\nfinalizando_lasso %&gt;% workflowsets::collect_predictions()\n\n\n# A tibble: 268 × 5\n     .pred id                .row charges .config             \n     &lt;dbl&gt; &lt;chr&gt;            &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n 1  3809.  train/test split     4  21984. Preprocessor1_Model1\n 2  3225.  train/test split    11   2721. Preprocessor1_Model1\n 3 35034.  train/test split    12  27809. Preprocessor1_Model1\n 4  4453.  train/test split    13   1827. Preprocessor1_Model1\n 5   686.  train/test split    16   1837. Preprocessor1_Model1\n 6  1921.  train/test split    18   2395. Preprocessor1_Model1\n 7  2827.  train/test split    23   1137. Preprocessor1_Model1\n 8    80.1 train/test split    29   2775. Preprocessor1_Model1\n 9 39149.  train/test split    40  48173. Preprocessor1_Model1\n10  6985.  train/test split    48   3557. Preprocessor1_Model1\n# ℹ 258 more rows\n\n\n\n\nCode\n# Visualizando predições do modelo Elastic Net\nfinalizando_elastic %&gt;% workflowsets::collect_predictions()\n\n\n# A tibble: 268 × 5\n     .pred id                .row charges .config             \n     &lt;dbl&gt; &lt;chr&gt;            &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n 1  3794.  train/test split     4  21984. Preprocessor1_Model1\n 2  3271.  train/test split    11   2721. Preprocessor1_Model1\n 3 34950.  train/test split    12  27809. Preprocessor1_Model1\n 4  4453.  train/test split    13   1827. Preprocessor1_Model1\n 5   688.  train/test split    16   1837. Preprocessor1_Model1\n 6  1966.  train/test split    18   2395. Preprocessor1_Model1\n 7  2834.  train/test split    23   1137. Preprocessor1_Model1\n 8    73.2 train/test split    29   2775. Preprocessor1_Model1\n 9 39060.  train/test split    40  48173. Preprocessor1_Model1\n10  6989.  train/test split    48   3557. Preprocessor1_Model1\n# ℹ 258 more rows\n\n\n\n\nCode\n# Visualizando predições do modelo KNN\nfinalizando_knn %&gt;% workflowsets::collect_predictions()\n\n\n# A tibble: 268 × 5\n    .pred id                .row charges .config             \n    &lt;dbl&gt; &lt;chr&gt;            &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n 1  5659. train/test split     4  21984. Preprocessor1_Model1\n 2  2511. train/test split    11   2721. Preprocessor1_Model1\n 3 30708. train/test split    12  27809. Preprocessor1_Model1\n 4  3901. train/test split    13   1827. Preprocessor1_Model1\n 5  2186. train/test split    16   1837. Preprocessor1_Model1\n 6  2038. train/test split    18   2395. Preprocessor1_Model1\n 7  2203. train/test split    23   1137. Preprocessor1_Model1\n 8  5770. train/test split    29   2775. Preprocessor1_Model1\n 9 41128. train/test split    40  48173. Preprocessor1_Model1\n10  2797. train/test split    48   3557. Preprocessor1_Model1\n# ℹ 258 more rows\n\n\n\n\nCode\n# Extraindo o modelo Ridge\nmodelo_final_ridge &lt;- \n  finalizando_ridge %&gt;% \n  extract_fit_parsnip()\n\n# Extraindo o modelo Lasso\nmodelo_final_lasso &lt;- \n  finalizando_lasso %&gt;% \n  extract_fit_parsnip()\n\n# Extraindo o modelo Elastic Net\nmodelo_final_elastic &lt;- \n  finalizando_elastic %&gt;% \n  extract_fit_parsnip()\n\n# Extraindo o modelo KNN\nmodelo_final_knn &lt;- \n  finalizando_knn %&gt;% \n  extract_fit_parsnip()\n\n\n\n\nCode\n# Fazendo previsões \ndados_novos &lt;- dados[sample(1:nrow(dados), 10), -7]\n\n# Fazendo previsões com o modelo Ridge\npredict(finalizando_ridge$.workflow[[1]], \n                           new_data = dados_novos)\n\n\n# A tibble: 10 × 1\n    .pred\n    &lt;dbl&gt;\n 1 13401.\n 2 11853.\n 3 31753.\n 4  2863.\n 5 14363.\n 6  2359.\n 7 33426.\n 8 36616.\n 9 16854.\n10 12328.\n\n\n\n\nCode\n# Fazendo previsões com o modelo Lasso\npredict(finalizando_lasso$.workflow[[1]], \n                           new_data = dados_novos)\n\n\n# A tibble: 10 × 1\n    .pred\n    &lt;dbl&gt;\n 1 13368.\n 2 11880.\n 3 33127.\n 4  2067.\n 5 14574.\n 6  1522.\n 7 34993.\n 8 38380.\n 9 17129.\n10 12357.\n\n\n\n\nCode\n# Fazendo previsões com o modelo Elastic Net\npredict(finalizando_elastic$.workflow[[1]], \n                           new_data = dados_novos)\n\n\n# A tibble: 10 × 1\n    .pred\n    &lt;dbl&gt;\n 1 13354.\n 2 11915.\n 3 33086.\n 4  2077.\n 5 14615.\n 6  1520.\n 7 34914.\n 8 38308.\n 9 17150.\n10 12339.\n\n\n\n\nCode\n# Fazendo previsões com o modelo KNN\npredict(finalizando_knn$.workflow[[1]], \n                           new_data = dados_novos)\n\n\n# A tibble: 10 × 1\n    .pred\n    &lt;dbl&gt;\n 1 14898.\n 2 12985.\n 3 39307.\n 4  2830.\n 5 12436.\n 6  3172.\n 7 34266.\n 8 43150.\n 9 11881.\n10 15496.\n\n\n\n\nCode\n# Adicionando as previsões com o modelo Ridge ao conjunto de dados original\naugment(finalizando_ridge$.workflow[[1]], \n                         new_data = dados_novos)\n\n\n# A tibble: 10 × 7\n    .pred   age sex      bmi children smoker region   \n    &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;  &lt;dbl&gt;    &lt;int&gt; &lt;chr&gt;  &lt;chr&gt;    \n 1 13401.    55 male    37.3        0 no     southwest\n 2 11853.    63 female  23.1        0 no     northeast\n 3 31753.    30 female  39.0        3 yes    southeast\n 4  2863.    22 female  28.0        0 no     southeast\n 5 14363.    62 female  31.7        0 no     northeast\n 6  2359.    19 male    28.7        0 no     southwest\n 7 33426.    57 female  29.8        0 yes    southeast\n 8 36616.    48 male    40.6        2 yes    northwest\n 9 16854.    52 female  44.7        3 no     southwest\n10 12328.    63 female  25.1        0 no     northwest\n\n\n\n\nCode\n# Adicionando as previsões com o modelo Lasso ao conjunto de dados original\naugment(finalizando_lasso$.workflow[[1]], \n                         new_data = dados_novos)\n\n\n# A tibble: 10 × 7\n    .pred   age sex      bmi children smoker region   \n    &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;  &lt;dbl&gt;    &lt;int&gt; &lt;chr&gt;  &lt;chr&gt;    \n 1 13368.    55 male    37.3        0 no     southwest\n 2 11880.    63 female  23.1        0 no     northeast\n 3 33127.    30 female  39.0        3 yes    southeast\n 4  2067.    22 female  28.0        0 no     southeast\n 5 14574.    62 female  31.7        0 no     northeast\n 6  1522.    19 male    28.7        0 no     southwest\n 7 34993.    57 female  29.8        0 yes    southeast\n 8 38380.    48 male    40.6        2 yes    northwest\n 9 17129.    52 female  44.7        3 no     southwest\n10 12357.    63 female  25.1        0 no     northwest\n\n\n\n\nCode\n# Adicionando as previsões com o modelo Elastic Net ao conjunto de dados original\naugment(finalizando_elastic$.workflow[[1]], \n                         new_data = dados_novos)\n\n\n# A tibble: 10 × 7\n    .pred   age sex      bmi children smoker region   \n    &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;  &lt;dbl&gt;    &lt;int&gt; &lt;chr&gt;  &lt;chr&gt;    \n 1 13354.    55 male    37.3        0 no     southwest\n 2 11915.    63 female  23.1        0 no     northeast\n 3 33086.    30 female  39.0        3 yes    southeast\n 4  2077.    22 female  28.0        0 no     southeast\n 5 14615.    62 female  31.7        0 no     northeast\n 6  1520.    19 male    28.7        0 no     southwest\n 7 34914.    57 female  29.8        0 yes    southeast\n 8 38308.    48 male    40.6        2 yes    northwest\n 9 17150.    52 female  44.7        3 no     southwest\n10 12339.    63 female  25.1        0 no     northwest\n\n\n\n\nCode\n# Adicionando as previsões com o modelo KNN ao conjunto de dados original\naugment(finalizando_knn$.workflow[[1]], \n                         new_data = dados_novos)\n\n\n# A tibble: 10 × 7\n    .pred   age sex      bmi children smoker region   \n    &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;  &lt;dbl&gt;    &lt;int&gt; &lt;chr&gt;  &lt;chr&gt;    \n 1 14898.    55 male    37.3        0 no     southwest\n 2 12985.    63 female  23.1        0 no     northeast\n 3 39307.    30 female  39.0        3 yes    southeast\n 4  2830.    22 female  28.0        0 no     southeast\n 5 12436.    62 female  31.7        0 no     northeast\n 6  3172.    19 male    28.7        0 no     southwest\n 7 34266.    57 female  29.8        0 yes    southeast\n 8 43150.    48 male    40.6        2 yes    northwest\n 9 11881.    52 female  44.7        3 no     southwest\n10 15496.    63 female  25.1        0 no     northwest"
  }
]